---
title: "Тестирование статистических гипотез"
subtitle: "Линейные модели..."
author: "Марина Варфоломеева, Юта Тамберг, Вадим Хайтов"
date: "Осень `r format(Sys.Date(), '%Y')`"
output:
  xaringan::moon_reader:
    self_contained: true
    lib_dir: libs
    css: [ninjutsu, "assets/xaringan-themer.css", "assets/xaringan.css"]
    df_print: default
    nature:
      highlightStyle: googlecode
      highlightLines: true
      countIncrementalSlides: false
      titleSlideClass: [middle, left, inverse]
      beforeInit: "assets/macros.js"
    includes:
      in_header: "assets/xaringan_in_header.html"
      after_body: "assets/xaringan_after_body.html"
---

```{r setup, include = FALSE, cache = FALSE, purl = FALSE, fig.showtext = TRUE}
library(knitr)
opts_chunk$set(tidy = FALSE, warning = FALSE, message = FALSE, cache =TRUE)

source("assets/xaringan_setup.R")
library(xaringanExtra)
use_tile_view()
use_scribble()
use_search(show_icon = FALSE)
use_progress_bar(color = "#6d2b5e", location = "bottom", height = "10px")
use_freezeframe()
# use_webcam()
# use_panelset()
# use_extra_styles(hover_code_line = TRUE)

# http://tachyons.io/docs/
# https://roperzh.github.io/tachyons-cheatsheet/
use_tachyons()
```

```{r libs-funs, include = FALSE, cache = FALSE, purl = FALSE}
library("tidyverse")
library("cowplot")
library("ggplot2")
theme_set(theme_bw(base_size = 20))
library("scales")
library("grid")
ar <- arrow(type = 'closed', length = unit(0.15,'cm'))
arb <- arrow(type = 'closed', length = unit(0.15,'cm'), ends = 'both')

dt_limit <- function(x, alph = 0.05, df = 18, sides = 2, ncp = 0, what = "alpha") {
  #' Function to generate data for plotting with ggplot
  #' (non)central t distribution
  #' with shaded areas for alpha, beta and power
  #' Authors: Marina Varfolomeeva, Vadim Khaitov
  #' Usage inside stat_function:
  #' stat_function(fun = dt_limit,
  #'               args = list(alph = alpha, df = df, sides = sides),
  #'               geom = "area", fill = "red", alpha = 0.7)
  if(sides == 1) alph <- alph
  if(sides == 2) alph <- alph/2
  t_cr <- abs(qt(p = alph, df = df))

  if(what == "alpha"){
    y <- dt(x, df, ncp = ncp)
    y[!(x < -t_cr | x > t_cr)] <- NA
  }
  if(what == "beta"){
    y <- dt(x, df, ncp = ncp)
    y[!(x >= -t_cr & x <= t_cr)] <- NA
  }
  if(what == "power"){
    y <- dt(x, df, ncp = ncp)
    y[!(x < -t_cr | x > t_cr)] <- NA
  }
  return(y)
}

dnorm_limit <- function(x, alph = 0.05, mu = 0, sig = 1, sides = 2, what = "alpha") {
  #' Function to generate data for plotting with ggplot
  #' (non)central normal distribution
  #' with shaded areas for alpha, beta and power
  #' Authors: Marina Varfolomeeva, Vadim Khaitov
  #' Usage inside stat_function:
  #' stat_function(fun = dnorm_limit,
  #'               args = list(alph = alpha, mu = mu, sig = sig, sides = sides),
  #'               geom = "area", fill = "red", alpha = 0.7)
  if(sides == 1) alph <- alph
  if(sides == 2) alph <- alph/2
  z_cr <- abs(qnorm(p = alph, mean = mu, sd = sig))

  if(what == "alpha"){
    y <- dnorm(x, mean = mu, sd = sig)
    y[!(x <= -z_cr | x >= z_cr)] <- NA
  }
  if(what == "beta"){
    y <- dnorm(x, mean = mu, sd = sig)
    y[!(x >= -z_cr & x <= z_cr)] <- NA
  }
  if(what == "power"){
    y <- dnorm(x, mean = mu, sd = sig)
    y[!(x < -z_cr | x > z_cr)] <- NA
  }
  return(y)
}
```

## Тестирование гипотез

- Выборочное распределение среднего значения
- Как устроено тестирование гипотез
- t-статистика
- Применение t-теста
- Статистическая значимость

---


class: middle, center, inverse


# Оценка параметров распределения по выборке


---
## Задание


- Загрузите объект `population`. Это вектор, характеризующий размеры особей, в некоторой гипотетической популяции. 

```{r}
load("data/population.RData")
```


- Сделайте из этой совокупности случайную выборку в 5 измерений.

```{r}
my_sample <-  sample(x = population, size = 5)

my_sample  
```

- Определите среднее значение и среднеквадратичное отклонение.

```{r}
mean(my_sample)
sd(my_sample)
```

- Проведите такую выборку несколько раз.


---

## Выборочные оценки

- Изучая интересующую нас систему, мы не знаем значений параметров распределения, которое описывает поведение вероятности в **генральной совокупности** (*population*).

- Мы проводим **оценку** (*estimate*) этих параметров, используя **выборку** (*sample*).

- Выборка имеет ограниченный **объем**(*N*, или *n*).

- Выборка попадает в анализ в виде вектора значений $\{x_1, x_2, x_3, \dots , x_n\}$  

---

## Выборочные оценки

Выборка может быть описана с помощью "5 number statistic": 

--

- Min
- Q1
- Q2 (Median)
- Q3
- Max

---

## Выборочные оценки

Другой способ описания выборки 

--
- Среднее значение:  $\bar{x}=\frac{\Sigma{x_i} }{n}$

--
- Стандартное отклонение: $sd = \sqrt{\frac{\Sigma{(x_i - \bar{x})^2}}{n-1} }$ 

--

Если $x_i \in N(\mu, \sigma)$, то 

--
$$
\bar{x} \xrightarrow[n\to\infty]{} \mu
$$

--
$$
sd \xrightarrow[n\to\infty]{} \sigma
$$


---

class: middle, center, inverse

# Выборочная оценка среднего

???

Что мы можем сказать о среднем значении в генеральной совокупности, если у нас есть всего одна выборка? Центральная предельная теорема говорит, что если мы возьмем достаточно большую выборку из генеральной совокупности, то среднее значение будет нормально распределено. Особенно важно, что это правда даже если признак в совокупности имеет другое распределение. Повторные выборки. Зависимость точности оценки от объема выборки. Ошибка среднего SE (это иллюстрация теоремы центрального предела).

---

## Как можно судить о свойствах генеральной совокупности по выборке?

__Центральная предельная теорема__ (ЦПТ) говорит, что если мы возьмем достаточно большую выборку из генеральной совокупности, то среднее значение будет нормально распределено с параметрами $\mu_{\bar x}$ и $\sigma _{\bar{x}}$:

$$\bar X \sim N (\mu_{\bar x}, \sigma_{\bar x})$$

При чем $\sigma_{\bar x} = \frac{\sigma}{\sqrt{n}}$.

<br/>

__Важно__: это будет так при *больших объемах выборки* ( $n > 30$, или даже $n > 100$), даже если $x$ в генеральной совокупности не подчиняется нормальному распределению.

<br/>

Давайте проверим на опыте, так ли это.

---

## Цена алмазов

Представим, что данные об алмазах из датасета `diamonds` (пакет `gplot2`) — это генеральная совокупность.

Перед вами распределение цены алмазов. Давайте будем брать из этого распределения выборки и оценивать по ним среднее значение.

.pull-left[

```{r echo=FALSE, purl=FALSE}
data("diamonds")

X <- na.omit(diamonds$price)
sig <- sd(X)
mu <- mean(X)

lab <- paste('bar(x) ==', format(mu, nsmall = 0, digits = 1), '~~~sd ==', format(sig, nsmall = 0, digits = 1))

gg_population <- ggplot(data = data.frame(x = X), aes(x = x)) + 
  geom_histogram(fill = 'lightskyblue1', colour = 'black') + 
  geom_vline(xintercept = mu, colour = 'red', size = 2) +
  annotate('text', x = Inf, y = Inf, hjust = 1.1, vjust = 1.5, 
             label = lab, parse = T, size = 5) +
  labs(x = 'price', y = "count")
gg_population
```

]
.pull-right[
![:scale 75%](images/Diamond-age-bySteve-Jurvetson-on-Flickr.jpg)

.tiny[Diamond Age by Steve Jurvetson on Flickr
<!-- https://flic.kr/p/eRNcR -->]
]

---

.pull-left[

```{r gg-sample, echo=FALSE, purl=FALSE, fig.height = 10}
set.seed(83314197)
gg_sample_hist <- function(x, size) {
  id <- sample(x = length(x), size = size)
  my_mean <- mean(x[id])
  ggplot(data = data.frame(x = x[id]), aes(x = x)) + 
    geom_histogram(binwidth = 50, fill = 'grey40', colour = 'grey40') + 
    geom_vline(xintercept = mu, colour = 'red', size = 2) +
    geom_vline(xintercept = my_mean, colour = 'yellow3', size = 2) + 
    annotate('text', x = Inf, y = Inf, hjust = 3.1, vjust = 1.5, 
             label = paste('n ==', size), 
             parse = T, size = 5) +
        annotate('text', x = Inf, y = Inf, hjust = 1.1, vjust = 1.5, 
             label = paste('bar(x) ==', format(my_mean, nsmall = 2, digits = 2)), 
             parse = T, size = 5) + labs(y = "count")
}

gg_void <- ggplot() + theme_void()

n <- 20
# gg_sample_hist(X, n, xlim = c(30, 70))
plot_grid(gg_population + coord_cartesian(xlim = c(-1, max(X))) + theme(axis.title.x = element_blank()),
          gg_sample_hist(X, n) + coord_cartesian(xlim = c(-1, max(X))) + theme(axis.title.x = element_blank()), 
          gg_sample_hist(X, n) + coord_cartesian(xlim = c(-1, max(X))) + theme(axis.title.x = element_blank()), 
          gg_sample_hist(X, n) + coord_cartesian(xlim = c(-1, max(X))) + theme(axis.title.x = element_blank()), 
          gg_sample_hist(X, n) + coord_cartesian(xlim = c(-1, max(X))) + theme(axis.title.x = element_blank()), 
          gg_sample_hist(X, n) + coord_cartesian(xlim = c(-1, max(X))) + labs(x = 'price'), 
          ncol = 1, align = 'v', rel_heights = c(1, 1, 1, 1, 1, 1.2))
```

]
.pull-right[

## Средние в выборках

Средние в выборках отличаются от среднего в генеральной совокупности.

Если взять много выборок определенного размера, можно построить распределение выборочных средних.

<br/>

Как изменится форма распределения выборочных средних при изменении объема выборки?
]

---



.pull-left[

```{r gg-many-sampling-distr, echo=FALSE, purl=FALSE, fig.height=10}
# Функция, которая берет выборку объемом sample_size из вектора x и возвращает ее среднее значение
sample_mean <- function(x, size){
  id <- sample(x = length(x), size)
  my_mean <- mean(x[id])
  return(my_mean)
}

gg_sample_means <- function(x, n_samples, size){
  # Считаем средние значения для большого числа выборок
  my_means <- replicate(n = n_samples, expr = sample_mean(x, size))
  mean_of_means <- mean(my_means)
  sd_of_means <- sd(my_means)
  ggplot(data = data.frame(means = my_means), aes(x = means)) + 
    geom_histogram(binwidth = 4, fill = 'yellow3', alpha = 0.3, color = 'black') + 
    geom_vline(xintercept = mu, colour = 'red', size = 3) +
    geom_vline(xintercept = mean_of_means, colour = 'gold1', size = 1.5) + 
    annotate('text', x = -Inf, y = Inf, hjust = -0.1, vjust = 1.5, 
             label = paste('n ==', size), 
             parse = T, size = 5) +
        annotate('text', x = Inf, y = Inf, hjust = 1.1, vjust = 1.5, 
             label = paste('bar(x) ==', format(mean_of_means, nsmall = 2, digits = 2), '~~~sd ==', format(sd_of_means, nsmall = 2, digits = 2)), 
             parse = T, size = 5) +
    labs(y = "count")
}
n_samples <- 500
plot_grid(gg_population + coord_cartesian(xlim = c(0, 20000)), 
          gg_sample_means(x = X, n_samples = n_samples, size = 2) + 
            coord_cartesian(xlim = c(0, 20000)) + theme(axis.title.x = element_blank()), 
          gg_sample_means(x = X, n_samples = n_samples, size = 4) + 
            coord_cartesian(xlim = c(0, 20000)) + theme(axis.title.x = element_blank()), 
          gg_sample_means(x = X, n_samples = n_samples, size = 10) + 
            coord_cartesian(xlim = c(0, 20000)) + theme(axis.title.x = element_blank()), 
          gg_sample_means(x = X, n_samples = n_samples, size = 30) + 
            coord_cartesian(xlim = c(0, 20000)) + labs(x = 'sample mean'), 
          ncol = 1, align = 'v', rel_heights = c(1, 1, 1, 1, 1.2))
```


]
.pull-right[

### Распределение выборочных средних при разных объемах выборки

$$\bar X \sim N (\mu_{\bar x}, \sigma_{\bar x})$$

$\mu_{\bar x} = \mu$ — среднее значение выборочных средних стремится к среднему в генеральной совокупности.

$\sigma_{\bar x} =  \sigma / \sqrt{n}$ — стандартное отклонение в $\sqrt{n}$ раз меньше стандартного отклонения в генеральной совокупности.

$\sigma_{\bar x}$ называют стандартной ошибкой среднего и обозначают $SE _{\bar{x}}$.


]

---

## Центральная предельная теорема очень важна в статистике

.pull-left[

```{r echo=FALSE, purl=FALSE}
gg_sample_means(x = X, n_samples = n_samples, size = 100) + labs(x = 'sample means')
```

]
.pull-right[

$$\bar X \sim N (\mu, \sigma / \sqrt{n})$$

Пользуясь ее выводами, мы сможем:

- строить доверительные интервалы
- тестировать гипотезы

]

---

class: middle, center, inverse

# Доверительный интервал

---

## Если выполняется центральная предельная теорема... <br/><br/>

.pull-left-60[

```{r echo=FALSE, purl=FALSE, opts.label='fig.wider.taller'}
labs_x <- c(expression(-3*sigma / sqrt(n)), expression(-2*sigma / sqrt(n)), expression(-sigma / sqrt(n)), expression(bar(x)), expression(sigma / sqrt(n)), expression(2*sigma / sqrt(n)), expression(3*sigma / sqrt(n)))

gg_conf_0 <- ggplot(data = data.frame(z = -4:4), aes(x = z)) +
  stat_function(fun = dnorm, colour = 'steelblue', size = 1) + 
  scale_x_continuous(breaks = -3:3, sec.axis = sec_axis(~., breaks = -3:3, labels = labs_x, name = 'Распределение\nвыборочных средних')) +
  scale_y_continuous('Плотность вероятности') +
  coord_cartesian(ylim = c(0, 0.47), xlim = c(-3.6, 3.6))

gg_conf_0
```

]
.pull-right-40[

Было 

$$\bar X \sim N(\mu, \sigma/ \sqrt{n})$$

После стандартизации:

$$\frac{\bar X - \mu}{\sigma / \sqrt{n}} \sim N(0, 1)$$

Стандартизованное распределение выборочных средних — это стандартное нормальное распределение.

]

---

##  Доверительный интервал <br/>из нормального распределения

.pull-left-60[
```{r echo=FALSE, purl=FALSE, opts.label='fig.wider.taller'}
gg_conf_1 <- gg_conf_0 +
  stat_function(geom = 'area', fun = dnorm, xlim = c(-1.96, 1.96),
                fill = 'steelblue', alpha = 0.5) +
  annotate('text', label = 'P == 0.95', parse = T,
           x = 0, y = 0.1, size = 5) +
  annotate('text', label = '0.025', parse = T, size = 5,
           x = c(-2.2, 2.2), y = 0.01)
gg_conf_1
```


]
.pull-right-40[

--- это интервал, в который попадает заданный процент выборочных средних.

В 95% доверительный интервал попадает выборочное среднее в 95% *повторных* выборок.

<br/>

Как найти этот интервал?

]

---

##  Доверительный интервал <br/>из нормального распределения

.pull-left-60[

```{r echo=FALSE, purl=FALSE, opts.label='fig.wider.taller'}
gg_conf_2 <- gg_conf_1 + 
  geom_vline(xintercept = c(-1.96, 1.96), linetype = 'dashed') +
  annotate(geom = 'text', label = c('-z[0.05]==-1.96', 'z[0.05]==1.96'), hjust = c(1.03, -0.03),
           x = c(-1.96, 1.96), y = 0.1, parse = TRUE, size = 5)

gg_conf_2
```

]
.pull-right-40[

$$\bar {x} \pm z_{\alpha} \cdot \sigma / \sqrt{n}$$

Чтобы найти границы 95% доверительного интервала, нужно найти квантили стандартного нормального распределения, которые соответствуют вероятностям 0.025 и 0.975

```{r}
qnorm(p = c(0.025, 0.975))
```


$z_{0.05} = 1.96$

95% выборочных средних в повторных выборках будут лежать в пределах $\pm 1.96$ стандартных ошибок вокруг среднего значения.

]

---

## Условия применимости нормального распределения для доверительного интервала

1.Должна быть известна $\sigma$ в генеральной совокупности.

2.Должны выполняться условия, при которых справедлива ЦПТ:

- Наблюдения в выборке должны быть независимы друг от друга.

- Большой объем выборки **или** нормальное распределение $x$

---

## Если $\pmb \sigma$ не известна

Если $\sigma$ в генеральной совокупности не известна, ее можно оценить по выборочному стандартному отклонению $sd$.

$$\sigma / \sqrt{n} \approx sd/\sqrt{n}$$

После стандартизации:

$$\frac{\bar X - \mu}{SE_{\bar x}} = \frac{\bar X - \mu}{sd / \sqrt{n}} \sim t_{df = n - 1}$$


стандартизованное распределение выборочных средних подчиняется $t$-распределению с числом степеней свободы $df = n - 1$

---

## _t_-распределение, или распределение Стьюдента

.pull-left-55[

```{r echo=FALSE, purl=FALSE, opts.label='fig.wider.taller'}
ggplot(data = data.frame(t = -4 : 4), aes(x = t)) +
  stat_function(aes(color = 't, df = 3', linetype = 't, df = 3'), 
                fun = dt, args = list(df = 3), size = 1.5) +
  stat_function(aes(color = 't, df = 10', linetype = 't, df = 10'), 
                fun = dt, args = list(df = 10), size = 1.5) +
  stat_function(aes(color = 'Z', linetype = 'Z'), size = 1.5,
                fun = dnorm) +
  scale_color_manual(
    'Распределение',
    values = c('Z' = 'steelblue', 
               't, df = 10' = 'orange',
               't, df = 3' = 'red')) + 
  scale_linetype_manual(
    'Распределение', 
    values = c('Z' = 2, 't, df = 10' = 1, 't, df = 3' = 1)) + 
  labs(y = 'Плотность вероятности') +
  theme(legend.position = c(0.8, 0.75), 
        legend.box.background = element_blank(),
        legend.background = element_blank())
```

- Симметричное колоколообразное распределение с толстыми хвостами. 
- Единственный параметр — число степеней свободы (для доверительного интервала $df = n - 1$).
- При увеличении объема выборки $t$-распределение приближается к нормальному.


]
.pull-right-45[
![](images/William_Sealy_Gosset.png)

William Sealy Gosset

]

---

## Доверительный интервал из _t_-распределения

.pull-left-55[

```{r echo=FALSE, purl=FALSE, opts.label='fig.wider.taller'}
n <- 10
lims <- qt(p = c(0.025, 0.975), df = n - 1)
labs <- format(lims, digits = 2, nsmall = 2)
labs_x <- c(expression(-3*s / sqrt(n)), expression(-2*s / sqrt(n)), expression(-s / sqrt(n)), expression(bar(x)), expression(s / sqrt(n)), expression(2*s / sqrt(n)), expression(3*s / sqrt(n)))

gg_conf_0 <- ggplot(data = data.frame(t = -4:4), aes(x = t)) +
  stat_function(fun = dt, args = list(df = n - 1), colour = 'red', size = 1) +
  scale_x_continuous(breaks = -3:3, sec.axis = sec_axis(~., breaks = -3:3, labels = labs_x, name = 'Выборочное распределение средних')) +
  scale_y_continuous('Плотность вероятности') +
  coord_cartesian(ylim = c(0, 0.47), xlim = c(-3.6, 3.6))
gg_conf_1 <- gg_conf_0 +
  stat_function(geom = 'area', fun = dt, args = list(df = n - 1), xlim = lims,
                fill = 'red', alpha = 0.5) +
  annotate('text', label = 'P == 0.95', parse = T,
           x = 0, y = 0.1, size = 5) +
  annotate('text', label = '0.025', parse = T, size = 5,
           x = lims, y = 0.01, hjust = c(1.03, -0.03))
gg_conf_2 <- gg_conf_1 +
  geom_vline(xintercept = lims, linetype = 'dashed') +
  annotate(geom = 'text', label = c(paste('-t[0.05, 9]==', labs[1]), paste('t[0.05, 0]==', labs[2])), hjust = c(1.03, -0.03),
           x = lims, y = 0.1, parse = TRUE, size = 5)
gg_conf_2 +
  annotate('path', x = lims, y = rep(0.42, 2), arrow = arb) +
  annotate('text', label = paste('Для~n==10~~~~~~~bar(x)%+-%', labs[2], '*~sigma / sqrt(n)'), vjust = -0.5, x = 0, y = 0.42, parse = TRUE, size = 5)
```

]
.pull-right-45[

Обязательно используется, если:

- Объем выборки мал.
- $\sigma$ не известна.

$$\bar {x} \pm t_{\alpha, df} \cdot s / \sqrt{n}$$

$df = n - 1$

<br/><br/><br/><br/><br/><br/>
]

Условия применимости

Выполняются условия, при которых справедлива ЦПТ:

- Наблюдения в выборке независимы друг от друга.
- Большой объем выборки и нет "выбросов" **или** нормальное распределение $x$

---

## Смысл 95% доверительного интервала

.pull-left[

```{r gg-many-lims, echo=FALSE, purl=FALSE, opts.label='fig.medium.tall'}
library(dplyr)
set.seed(14934)
# Генеральная совокупность для симуляции
x <- population 
x <-  rnorm(10000, mean = 170, sd = 5)
mu <- round(mean(x), 0)
# Функция, которая берет выборку объемом sample_size из вектора x и возвращает ее среднее значение и доверительный интервал (по t)
sample_mean_ci <- function(x, size){
  id <- sample(x = length(x), size)
  my_mean <- mean(x[id])
  ci <- my_mean + qt(p = c(0.025, 0.975), df = size - 1)
  res <- c(my_mean, ci)
  names(res) <- c('sample_mean', 'lower', 'upper')
  return(res)
}


n_samples <- 100
sample_size <- 20
means_ci <- replicate(n = n_samples, expr = sample_mean_ci(x, size = sample_size))
dfr_means <- data.frame(t(means_ci)) %>%
  mutate(interval = 1:n_samples,
         inside = mu >= lower & mu <= upper,
         inside = factor(inside, levels = c(TRUE, FALSE), labels = c('Да', 'Нет')))
perc <- round(mean(dfr_means$inside == 'Да') * 100, 1)

gg_many_lims <- ggplot(data = dfr_means) +
  geom_segment(aes(x = interval, y = lower, xend = interval, yend = upper, colour = inside)) +
  geom_hline(yintercept = mean(x), colour = 'red', size = 1) +
  scale_y_continuous('', breaks = mu, labels = expression(mu)) +
  labs(x = 'Порядковый номер интервала в симуляции', y = 'x',
       color = 'Включает ли\nинтервал\nистинное\nсреднее \nзначение?') +
  coord_flip() +
    scale_x_reverse()

gg_many_lims + scale_color_manual(values = c("red", "blue"))
```


]
.pull-right[

- Для примера возьмем данные из объекта `population`. Здесь известно, что $\mu = `r mu`$.

- Симулируем взятие многих выборок из этой генеральной совокупности.

- Среднее в генеральной совокупности — это фиксированная величина (она либо попала в интервал, либо нет.

- Доверительный интервал — случайная величина.


- В *повторных выборках* одинакового объема $\approx 95\%$ всех доверительных интервалов "накроют" истинное среднее значение.

]

---

## Расчет и изображение доверительного интервала в R

```{r echo=TRUE, eval=-1}
library(ggplot2)
data("diamonds")

# цена бриллиантов хорошего качества огранки
good <- diamonds$price[diamonds$cut == "Good"] 

.mean <- mean(good)                  # выборочное среднее
.n <- length(good)                   # объем выборки
SE <- sd(good)/ sqrt(.n)             # стандартная ошибка
t_crit <- qt(p = 0.975, df = .n - 1) # критич. зн. t для данного n и p = 0.95
err <- t_crit * SE                   # предел погрешности
err
# Границы доверительного интервала
.mean - err
.mean + err
```

Можем записать среднюю цену бриллиантов хорошей огранки и ее доверительный интервал:
$`r round(.mean, 1)` \pm `r round(err, 1)` (\pm SE)$ 

---

## Строим доверительные интервалы в ggplot

```{r echo=TRUE, eval=-1, opts.label='fig.wider'}
theme_set(theme_bw())
ggplot(data = diamonds, aes(x = cut, y = price)) +
  stat_summary(geom = 'pointrange', fun.data = mean_cl_normal)
```

---

## Задание 1

Посчитайте среднюю цену и доверительный интервал для бриллиантов с такими свойствами (*одновременно*):

- качество огранки (`cut`) идеальное (`Ideal`)
- прозрачность (`clarity`) наивысшая (`IF`)

Постройте график средней цены с доверительными интервалами для бриллиантов разного качества огранки и прозрачности.

---

## Решение

Вычислим границы доверительного интервала

```{r purl=FALSE, echo=TRUE}
ideal <- diamonds$price[diamonds$cut == 'Ideal' & diamonds$clarity == 'IF'] 

.mean <- mean(ideal)                  # выборочное среднее
.n <- length(ideal)                   # объем выборки, если нет NA
SE <- sd(ideal)/ sqrt(.n)             # стандартная ошибка
t_crit <- qt(p = 0.975, df = .n - 1) # критич. зн. t для данного n и p = 0.95
err <- t_crit * SE                   # предел погрешности
err
# Границы доверительного интервала
.mean - err
.mean + err
```

---

## Решение: cпособ 1 (некрасивый, требует доработки)

Теперь можно построить график средней цены с доверительными интервалами для бриллиантов разного качества огранки и прозрачности. Для этого нужно к предыдущему графику добавить информацию о прозрачности.

```{r purl=FALSE, echo=TRUE, opts.label='fig.wider'}
ggplot(data = diamonds, aes(x = cut, y = price, colour = clarity)) +
  stat_summary(geom = 'pointrange', fun.data = mean_cl_normal)
```



---

## Решение: cпособ 1 (доработка)

Теперь можно построить график средней цены с доверительными интервалами для бриллиантов разного качества огранки и прозрачности. Для этого нужно к предыдущему графику добавить информацию о прозрачности.

```{r purl=FALSE, echo=TRUE, opts.label='fig.wider'}
ggplot(data = diamonds, aes(x = cut, y = price, colour = clarity)) +
  stat_summary(geom = 'pointrange', fun.data = mean_cl_normal, position = position_dodge(width = 0.5))
```

---

## Решение: cпособ 2 (удовлетворительный)

```{r purl=FALSE, echo=TRUE, opts.label='fig.wider', fig.height=5.6}
ggplot(data = diamonds, aes(x = cut, y = price, colour = clarity)) +
  stat_summary(geom = 'pointrange', fun.data = mean_cl_normal) +
  facet_wrap(~ clarity) +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
```

Что странного в этой картинке?

--

Осторожно! Группы могут быть неоднородны: в каждой группе варьирует размер алмазов.  

---

## Статистика по группам при помощи пакета `dplyr`

На примере доверительных интервалов:

```{r }
library(dplyr)

smr_diamonds <- diamonds %>%             # данные
  group_by(cut, clarity) %>%             # группируем
  summarize(
    .mean = mean(price),                 # выборочное среднее
    .n = n(),                            # объем выборки
    SE = sd(price) / sqrt(.n),           # стандартная ошибка
    t_crit = qt(p = 0.975, df = .n - 1), # критич. зн. t
    err = t_crit * SE,                   # предел погрешности
    lower = .mean - err,  #  нижняя граница доверительного интервала
    upper = .mean + err   # верхняя граница доверительного интервала
  )

head(smr_diamonds)
```

---

class: middle, center, inverse

# Как устроено тестирование гипотез

---

## Сравнение выборок

Различия между выборками не всегда видны невооружённым глазом.

![](images/tres-caracoles-by-Alberto-Villen-on-freeimages.com.jpg)
![](images/tres-caracoles-by-Alberto-Villen-on-freeimages.com.jpg)

.tiny[tres caracoles by Alberto Villen on Freeimages.com]

---

## Нулевая и альтернативная гипотезы

Это первый шаг

![](images/tres-caracoles-by-Alberto-Villen-on-freeimages.com.jpg)
![](images/tres-caracoles-by-Alberto-Villen-on-freeimages.com.jpg)

.tiny[tres caracoles by Alberto Villen on Freeimages.com]

--

- Нулевая гипотеза $H_0$ чаще всего формулируется как **отсутствие различий** между сравниваемыми объектами. Например: Улитки из обеих популяций одинакового размера

- Альтернативная гипотеза $H_A$ формулируется как **присутствие различий**, она обратна нулевой гипотезе, т.е. включает все остальные случаи. Например: Улитки из обеих популяций разного размера.

---

## Нулевая и альтернативная гипотезы — это "два мира"

Вне зависимости от нас, реальность может находиться в одном из двух состояний:

.pull-left[
- $H_0$ верна, улитки одинаковы

![:scale 45%](images/tres-caracoles-by-Alberto-Villen-on-freeimages.com.jpg)
![:scale 45%](images/tres-caracoles-by-Alberto-Villen-on-freeimages.com.jpg)
]
.pull-right[
- $H_0$ неверна, улитки различаются 

![:scale 45%](images/tres-caracoles-by-Alberto-Villen-on-freeimages.com.jpg)
![:scale 30%](images/tres-caracoles-by-Alberto-Villen-on-freeimages.com.jpg)
]

<br />

--

После статистического теста мы принимаем решение о том, принять или отвергнуть $H_0$. Но это решение не обязательно окажется верным. Возможно четыре исхода:

.pull-left[
В мире где улитки одинаковы <br/>( $H_0$ верна) мы можем:  
- принять $H_0$ (верное решение),  
- отвергнуть $H_0$ (ошибка).
]
.pull-right[
В мире где улитки различаются <br/>( $H_A$ верна), мы можем:  
- принять $H_0$ (ошибка),  
- либо отвергнуть $H_0$ (верное решение).
]

---

## Верные и неверные решения

.pull-left[
**Ошибка I рода: нашли то, чего нет**
]
.pull-right[
**Ошибка II рода: не нашли то, что было**
]

| 	| $H_0$ верна |	$H_0$ неверна |
|:-----:|:-----:|:-----:|
| Отклонить H0 | Ошибка I рода с вероятностью <span class="orange">&alpha;</span></br>Ложно-положительный результат | 	Верно |
| Сохранить H0 | Верно | Ошибка II рода с вероятностью <span class= "blue">&beta;</span> </br> Ложно-отрицательный результат |

--

Пока мы будем говорить о том, как контролируют уровень **Ошибок I рода**. 
Про **Ошибки II рода** и **Power analysis** читайте дополнительную литературу.   

---

## Тестирование гипотез: Тестовые статистики

--

#### 1. Формулируем нулевую и альтернативную гипотезы.

Гипотезы выражаются математически в виде тестовых статистик. На этом этапе мы делаем определенные допущения.

--

#### 2. Проверяем __условия применимости__ тестовой статистики.

--

#### 3. По реальным данным вычисляем __эмпирическое значение тестовой статистики__.

--

Дальше мы должны ответить на вопрос:

**Насколько вероятно получить _такое или более экстремальное_ эмпирическое значение, если верна нулевая гипотеза  $H_0$?**

#### 4. Строим теоретическое распределение тестовой статистики для случая, когда верна $H_0$, и оцениваем по нему уровень значимости.

--

#### 5. Решаем сохранить или отвергнуть $H_0$.

Увы, мы не сможем узнать, какая гипотеза верна, но поймем, насколько с ней согласуются исходные данные.

---

class: middle, center, inverse

# Одновыборочный *t*-тест

---

## Размер кладки черепах

Разберемся с одновыборочным $t$-тестом на вымышленном примере.

```{r echo=FALSE, purl=FALSE}
n <- 35
# set.seed(181257)
# X <- round(rnorm(n, mean = 9.2, sd = 2.5))
X <- c(10, 11, 10, 7, 8, 7, 9, 8, 11, 11, 12, 8, 6, 7, 10, 11, 9, 
10, 7, 11, 11, 12, 11, 9, 4, 12, 9, 6, 9, 6, 9, 7, 8, 10, 9)
x <- mean(X)
s <- sd(X)
mu <- 8
```

Представьте, что в [одной статье](https://edis.ifas.ufl.edu/publication/UW441#:~:text=Reproductive%20rate%3A%20Clutch%20sizes%20range,to%20100%20years%20in%20captivity.) сказано, что средняя плодовитость черепах определенного вида — `r mu` яиц в кладке.

В вашей выборке из $`r n`$ черепах — $\bar x = `r x`$, $sd = `r s`$.

```{r echo=FALSE, eval=FALSE}
mu <- 8
X <- c(10, 11, 10, 7, 8, 7, 9, 8, 11, 11, 12, 8, 6, 7, 10, 11, 9, 
10, 7, 11, 11, 12, 11, 9, 4, 12, 9, 6, 9, 6, 9, 7, 8, 10, 9)
(n <- length(X))
(x <- mean(X))
(s <- sd(X))
```

Отличается ли приведенное в статье значение от того, что наблюдается в изученной популяции. Можно ли считать, что авторы статьи изучали что-то иное (другой вид, или популяцию из иных условий).   

<!-- Отличается ли реальная плодовитость в обследованной вами популяции черепах от того, что указано в статье? -->

![](images/gopher-tortoise.jpg)


<small>Gopher Tortoise by Judy Gallagher on Flickr</small>
<!-- https://flic.kr/p/Q2ZozS -->


---

## Одновыборочный t-тест

- $H_0: \mu = \mu_0$ — Реальная средняя плодовитость черепах такая, как в статье.
- $H_A: \mu \ne \mu_0$ — Средняя плодовитость отличается от того, что написано в статье.

$\mu_0$ — это какое-то конкретное значение. В нашей задаче это — `r mu` яиц в кладке.

<br/>

$$t = \cfrac{\bar x - \mu}{ s / \sqrt{n} }$$

Если выполняется ЦПТ, то одновыборочная $t$-статистика подчиняется $t$-распределению  
с числом степеней свободы $df = n - 1$.

Условия применимости:

- Наблюдения в выборке должны быть независимы друг от друга.
- Объем выборки достаточно велик **или** величины нормально распределены.

### Задание 2

Проверьте условия применимости t-теста. Вычислите t и p.

---

## Проверяем, нормально ли распределение

```{r echo=FALSE, purl=FALSE}
library(car)
qqPlot(X, id = FALSE)
```

--

Нет оснований для сомнения, что наша выборка взята из генеральной совокупности с распределением отличающимся от нормального.

---

## Вычислим наблюдаемое значение $t$-статистики

$$t = \cfrac{\bar x - \mu}{ sd / \sqrt{n} }$$
Средняя плодовитость в выборке из `r n` черепах $\bar x = `r x`$, стандартное отклонение $s = `r s`$.
В статье указана плодовитость $`r mu`$.


```{r echo=FALSE}
t_val <- round((x - mu) / (s / sqrt(n)), 2)
p_val <- format(2*pt(-t_val, df = n - 1), digits = 1, nsmall = 3)
```


$$t = \cfrac{`r x` - `r mu`}{ `r s` / \sqrt{`r n`} } = `r t_val`$$

---

## Насколько это значение согласуется с $H_0$?

.pull-left[

```{r echo=FALSE, purl=FALSE, opts.label='fig.medium.taller'}
cols <- c('yellow2', 'red')
labs <- c(paste('p =', p_val), expression(alpha ==0.05))
mappings <- factor(c('p', 'alpha'), levels = c('p', 'alpha'), labels = labs)
names(cols) <- labs

gg_test_0 <- ggplot(data = data.frame(t = -4:4), aes(x = t)) + 
  stat_function(fun = dt, args = list(df = n - 1), colour = 'steelblue', size = 1) +
  scale_x_continuous(breaks = -4:4, 
                     sec.axis = sec_axis(~.  * (s / sqrt(n))+ mu, 
                                         name = 'Наблюдаемое значение',
                                         breaks = seq(2, 18, 1))) +
  coord_cartesian(ylim = c(0, 0.5), xlim = c(-3.8, 3.8)) +
  labs(y = 'Плотность вероятности')

gg_test_t <- gg_test_0 +
  # Выноски для t
  annotate(geom = 'segment', 
           x = c(-t_val, t_val), 
           y = dt(c(-t_val, t_val), df = n - 1) + 0.15,
           xend = c(-t_val, t_val), 
           yend = c(0, 0), 
           arrow = ar) +
    # Подпись t
  annotate(geom = 'text', label = c(paste('-t =', -t_val), paste('t =', t_val)),
           x = c(-t_val, t_val), 
           y = dt(c(-t_val, t_val), df = n - 1) + 0.15,
           vjust = -0.3, size = 5)

gg_test_p <- gg_test_t +
    # Площадь под кривой
  stat_function(geom = 'area', fun = dt, args = list(df = n - 1), 
                aes(fill = mappings[1]), xlim = c(-4, -t_val), alpha = 0.7) +
  stat_function(geom = 'area', fun = dt, args = list(df = n - 1), 
               aes(fill = mappings[1]), xlim = c(t_val, 4), alpha = 0.7) +
  scale_fill_manual('', values = cols[1], labels = labs[1]) +
  theme(legend.position = c(0, 1), legend.background = element_blank(), legend.justification = c(0, 1))
# gg_test_p

gg_test_alpha <- gg_test_0 + 
  geom_vline(xintercept = qt(c(0.025, 0.975), df = n - 1), linetype = 2) +
        # Уровень значимости
  stat_function(geom = 'area', fun = dt, args = list(df = n - 1), 
                aes(fill = mappings[2]), xlim = c(-4, qt(0.025, df = n - 1)), alpha = 0.3) +
  stat_function(geom = 'area', fun = dt, args = list(df = n - 1), 
                aes(fill = mappings[2]), xlim = c(qt(0.975, df = n - 1), 4), alpha = 0.3) +
   scale_fill_manual('', values = cols[2], labels = labs[2])+
  guides(fill = guide_legend(override.aes = list(alpha = 0.4))) +
  theme(legend.position = c(0, 1), legend.background = element_blank(), legend.justification = c(0, 1))
# gg_test_alpha

gg_test_alpha_p <- gg_test_t + 
  # Критический уровень значимости
  stat_function(geom = 'area', fun = dt, args = list(df = n - 1), 
                aes(fill = mappings[2]), xlim = c(-4, qt(0.025, df = n - 1)), alpha = 0.3) +
  stat_function(geom = 'area', fun = dt, args = list(df = n - 1), 
                aes(fill = mappings[2]), xlim = c(qt(0.975, df = n - 1), 4), alpha = 0.3) +
  # Значение p, уровень значимости
  stat_function(geom = 'area', fun = dt, args = list(df = n - 1), 
                aes(fill = mappings[1]), xlim = c(-4, -t_val), alpha = 0.9) +
  stat_function(geom = 'area', fun = dt, args = list(df = n - 1), 
                aes(fill = mappings[1]), xlim = c(t_val, 4), alpha = 0.9) +
  scale_fill_manual('', values = cols, labels = labs) +
  guides(fill = guide_legend(override.aes = list(alpha = 0.25)))+
  theme(legend.position = c(0, 1), legend.background = element_blank(), legend.justification = c(0, 1))

gg_test_t # реальное t
# gg_test_p # уровень значимости
# gg_test_alpha # критический уровень значимости
# gg_test_alpha_p # сравнение с уровнем значимости
```

]
.pull-right[

При $H_0$ значение $t$ будет близко к нулю.

Насколько необычны значения t меньше или больше $\pm `r t_val`$?

]

---

## Уровень значимости (_p_-value)

.pull-left[

```{r echo=FALSE, purl=FALSE, opts.label='fig.medium.taller'}
gg_test_p # Значение p
```

]
.pull-right[

__Уровень значимости__ — это вероятность получить значение $t$ меньше или больше данного, если бы $H_0$ была справедлива.

]



---

## Уровень значимости (_p_-value)

.pull-left[

```{r echo=FALSE, purl=FALSE, opts.label='fig.medium.taller'}
gg_test_p # Значение p
```

]
.pull-right[

Можно вычислить значение $p$

```{r purl=FALSE}
2 * ( 1 - pt(2.96, df = 35 - 1) )
```

Если бы плодовитость не отличалось от указанной в статье, получить $t$ меньше или больше $`r t_val`$ можно было бы с вероятностью $p = `r p_val`$. 

]

---

## Критический уровень значимости

.pull-left[

```{r echo=FALSE, purl=FALSE, opts.label='fig.medium.taller'}
gg_test_alpha +  geom_vline(xintercept = qt(c(0.025, 0.975), df = n - 1), linetype = 2)
```

]
.pull-right[

Критический уровень значимости $\alpha$ — это порог для принятия решений.

Обычно используют $\alpha = 0.05$. 

$\alpha$ - это допустимая вероятность **Ошибки I рода** (найти отличия там, где их нет).


Если $p \le \alpha$ — отвергаем $H_0$  и принимаем $H_A$.

Если $p > \alpha$ — сохраняем $H_0$,  не можем ее отвергнуть.

]

---

## Принимаем решение

.pull-left[

```{r echo=FALSE, purl=FALSE, opts.label='fig.medium.taller'}
gg_test_alpha_p
```

]
.pull-right[

Мы получили $p < \alpha$, поэтому отвергаем $H_0$ и принимаем $H_A$.

Указанная в статье плодовитость **статистически значимо** отличается от плодовитости в изученной нами популяции. Мы изучали что-то иное (другую генеральную совокупность)!

--

*At!* Лучше не использовать популярное словосочетание "*достоверно отличается*". Достоверные события - это события, вероятность которых равна 1. 
]

---

## Заблуждения о _p_-values

--

- Правда ли, что $p$ — вероятность того, что верна сама $H_0$?  

--

- Нет! Значение $p$ всегда считается __при условии, что $H_0$ верна__. Но $H_0$ может быть неверна.

<br/>

--

Правда ли, что $p$ — это вероятность получить такое значение статистики при справедливой $H_0$?

--

- Нет! Вероятность вычисляется как площадь под участком кривой.  Конкретное значение статистики — это точка и под ней нет площади.

<br/>

--

Правда ли, что если $p > 0.05$, то различий между группами на самом деле нет?  

--

- Нет! Это значит, что имеющиеся данные не позволяют отвергнуть нулевую гипотезу. Различия могут быть.

--

*p*-value - это всего лишь вероятность того, что *в мире, где справедлива $H_0$,* при повторных выборках из той же генеральной совокупности значение выбранной статистики (например *t*) будет больше или равно наблюдаемого в нашей выборке. 


---

class: middle, center, inverse


##############################################################
Внимание. Кусок лекции про power откладываем до луших времен

##############################################################

# Статистические ошибки при проверке гипотез

---

## Статистические ошибки при проверке гипотез

.pull-left[
**Ошибка I рода: нашли то, чего нет**
]
.pull-right[
**Ошибка II рода: не нашли то, что было**
]

| 	| $H_0$ верна |	$H_0$ неверна |
|:-----:|:-----:|:-----:|
| Отклонить H0 | Ошибка I рода с вероятностью <span class="orange">&alpha;</span></br>Ложно-положительный результат | 	Верно |
| Сохранить H0 | Верно | Ошибка II рода с вероятностью <span class= "blue">&beta;</span> </br> Ложно-отрицательный результат |

<br/>

Как эти ошибки выглядят на графике? Как они взаимосвязаны?


```{r power_alpha, echo = FALSE, purl = FALSE}
cols <- c('red', 'steelblue', 'green')
br <- c('alpha', 'beta', '1 - beta')
labs <- list(bquote(alpha), bquote(beta), bquote(1 - beta))
mappings <- factor(c('alpha', 'beta', 'power'), levels = c('alpha', 'beta', 'power'), labels = labs)
names(cols) <- labs

# Только нулевая
gg_H0 <- ggplot(data = data.frame(t = -7:7), aes(x = t)) +
  stat_function(fun = dt, args = list(df = n - 1), colour = 'steelblue', size = 1) +
  scale_x_continuous(breaks = -7:7) +
  coord_cartesian(ylim = c(0, 0.5), xlim = c(-3.6, 6.6)) +
  labs(y = 'Плотность вероятности') +
  theme(legend.position = c(0.8, 1), legend.background = element_blank(), legend.justification = c(0, 1))

# Нулевая и альтернативная
nc <- (x - mu)/(s/sqrt(n))
gg_H0A <- gg_H0 + stat_function(fun = dt,
                args = list(df = n - 1, ncp = nc),
                geom = "line", colour = 'steelblue', size = 1, linetype = 2) +
  annotate('text', label = 'H[0]', parse = TRUE, x = -Inf, y = Inf, hjust = - 0.5, vjust = 1.7, size = 5) +
  annotate('text', label = 'H[A]', parse = TRUE, x = Inf, y = Inf, hjust = 1.5, vjust = 1.7, size = 5) +
  annotate('path', x = c(-2.5, -0.5), y = c(0.43, 0.38), arrow = ar) +
  annotate('path', x = c(5.4, 3), y = c(0.43, 0.38), arrow = ar)
# gg_H0A

# Альфа
gg_alpha <- gg_H0 +
  geom_vline(xintercept = qt(c(0.025, 0.975), df = n - 1), linetype = 2) +
  # Уровень значимости
  stat_function(geom = 'area', fun = dt, args = list(df = n - 1),
                aes(fill = 'alpha'), xlim = c(-5, qt(0.025, df = n - 1)), alpha = 0.5) +
  stat_function(geom = 'area', fun = dt, args = list(df = n - 1),
                aes(fill = 'alpha'), xlim = c(qt(0.975, df = n - 1), 5), alpha = 0.5) +
  scale_fill_manual('', values = cols, labels = labs)
# gg_alpha

# Нулевая с альфой и альтернативная
gg_nc <- gg_alpha +
  stat_function(fun = dt,
                args = list(df = n - 1, ncp = nc),
                geom = "line", colour = 'steelblue', size = 1, linetype = 2)
# gg_nc

# Нулевая с альфой и альтернативная + бета
gg_beta <- gg_alpha +
  # beta
  stat_function(fun = dt,
                args = list(df = n - 1, ncp = nc),
                geom = "area", aes(fill = 'beta'), alpha = 0.7,
                xlim = qt(p = c(0.0275, 0.975), df = n - 1)) +
  # H_A curve
  stat_function(fun = dt,
                args = list(df = n - 1, ncp = nc),
                geom = "line", colour = "steelblue", size = 1, linetype = 2) +
  scale_fill_manual('', values = cols, labels = labs)
# gg_beta

# С меньшим уровнем значимости
gg_beta_1 <- gg_H0 +
  geom_vline(xintercept = qt(c(0.005, 0.995), df = n - 1), linetype = 2) +
    # Уровень значимости
  stat_function(geom = 'area', fun = dt, args = list(df = n - 1),
                aes(fill = 'alpha'), xlim = c(-5, qt(0.005, df = n - 1)), alpha = 0.5) +
  stat_function(geom = 'area', fun = dt, args = list(df = n - 1),
                aes(fill = 'alpha'), xlim = c(qt(0.995, df = n - 1), 5), alpha = 0.5) +
  scale_fill_manual('', values = cols, labels = labs) +
    # beta
  stat_function(fun = dt,
                args = list(df = n - 1, ncp = nc),
                geom = "area", aes(fill = 'beta'), alpha = 0.7,
                xlim = qt(p = c(0.005, 0.995), df = n - 1)) +
  # H_A curve
  stat_function(fun = dt,
                args = list(df = n - 1, ncp = nc),
                geom = "line", colour = "steelblue", size = 1, linetype = 2) +
  scale_fill_manual('', values = cols, labels = labs)
  # gg_beta_1

# Нулевая с альфой и альтернативная + бета + мощность
p_nc <- pt(qt(p = c(0.0275, 0.975), df = n - 1), df = n - 1, ncp = nc)
lims_nc <- qt(p = p_nc, df = n - 1, ncp = nc)
gg_power <- gg_beta +
  # power - upper
  stat_function(fun = dt,
                args = list(df = n - 1, ncp = nc),
                 geom = "area", aes(fill = '1 - beta'), alpha = 0.7,
                xlim = c(lims_nc[2], 6)) +
  # power- lower
  stat_function(fun = dt,
                args = list(df = n - 1, ncp = nc),
                geom = "area", aes(fill = '1 - beta'), alpha = 0.7,
                xlim = c(-6, lims_nc[1])) +
  scale_fill_manual('', values = cols, breaks = br, labels = labs)
# gg_power

x_1 <- 7.4
nc_1 <- (x_1 - mu)/(s/sqrt(n))
p_nc_1 <- pt(qt(p = c(0.0275, 0.975), df = n - 1), df = n - 1, ncp = nc_1)
lims_nc_1 <- qt(p = p_nc_1, df = n - 1, ncp = nc_1)

gg_power_1 <- gg_alpha +
  # beta
  stat_function(fun = dt,
                args = list(df = n - 1, ncp = nc_1),
                geom = "area", aes(fill = 'beta'), alpha = 0.7,
                xlim = qt(p = c(0.0275, 0.975), df = n - 1)) +
  # H_A curve
  stat_function(fun = dt,
                args = list(df = n - 1, ncp = nc_1),
                geom = "line", colour = "steelblue", size = 1, linetype = 2) +
  scale_fill_manual('', values = cols, labels = labs) +
  # power - upper
  stat_function(fun = dt,
                args = list(df = n - 1, ncp = nc_1),
                 geom = "area", aes(fill = '1 - beta'), alpha = 0.7,
                xlim = c(lims_nc_1[2], 7)) +
  # power- lower
  stat_function(fun = dt,
                args = list(df = n - 1, ncp = nc_1),
                geom = "area", aes(fill = '1 - beta'), alpha = 0.7,
                xlim = c(-7, lims_nc_1[1])) +
  scale_fill_manual('', values = cols, breaks = br, labels = labs) +
  annotate('segment', x = 0, y = 0.42, xend = nc_1, yend = 0.42, arrow = arb) +
  annotate('text', x = nc_1/2, y = 0.42, label = 'Эффект', vjust = -0.4)
# gg_power_1

# S и M ошибки при маленькой величине эффекта
x_2 <- 5.93
nc_2 <- (x_2 - mu)/(s/sqrt(n))
p_nc_2 <- pt(qt(p = c(0.0275, 0.975), df = n - 1), df = n - 1, ncp = nc_2)
lims_nc_2 <- qt(p = p_nc_2, df = n - 1, ncp = nc_2)

gg_sm <- gg_H0 +
  geom_vline(xintercept = qt(c(0.025, 0.975), df = n - 1), linetype = 2) +
  # H_A curve
  stat_function(fun = dt,
                args = list(df = n - 1, ncp = nc_2),
                geom = "line", colour = "steelblue", size = 1, linetype = 2) +
  # power - upper
  stat_function(fun = dt,
                args = list(df = n - 1, ncp = nc_2),
                geom = "area", aes(fill = '1 - beta'), alpha = 0.7,
                xlim = c(lims_nc_2[2], 7)) +
  # power- lower
  stat_function(fun = dt,
                args = list(df = n - 1, ncp = nc_2),
                geom = "area", aes(fill = '1 - beta'), alpha = 0.7,
                xlim = c(-7, lims_nc_2[1])) +
  scale_fill_manual('', values = cols, breaks = br, labels = labs) +
  geom_vline(xintercept = 0) +
  geom_vline(xintercept = nc_2, linetype = 'dotted') +
  annotate('segment', x = 0, y = 0.42, xend = nc_2, yend = 0.42, size = 2, colour = 'red') +
  annotate('segment', x = 0, y = 0.45, xend = qt(p = 0.975, df = n - 1), yend = 0.45, size = 2, colour = 'orange') +
  annotate('text', x = qt(p = 0.975, df = n - 1) / 2, y = 0.45, label = 'M', vjust = -0.4) +
  annotate('text', x = -3, y = 0.01, label = 'S', vjust = -0.4)  +
  coord_cartesian(ylim = c(0, 0.5), xlim = c(-3.6, 3.6))
# gg_sm
```

---

## Можно построить теоретические распределения <br/>при $H_0$ и $H_A$

```{r echo = FALSE, purl = FALSE, opts.label='fig.wide'}
gg_H0A
```

Распределение статистики, когда справедлива $H_0$, нам уже знакомо — его мы используем в тестах.

Но может быть справедлива $H_A$ и ее тоже можно описать своим распределением.

При помощи этих распределений можно определить вероятность ошибок различных типов.

---

## Ошибка I рода — <br/>найти различия там, где их нет

```{r echo = FALSE, purl = FALSE, opts.label='fig.wide'}
gg_nc
```

$\alpha$ (критический уровень значимости) — это вероятность ошибки I рода.

Если $H_0$ справедлива, то при $\alpha = 0.05$ мы отвергаем ее с 5% вероятностью.

Чтобы снизить вероятность таких ошибок, можно уменьшить $\alpha$.

---

## Ошибка II рода — <br/>не найти различий, где они есть

```{r echo = FALSE, purl = FALSE, opts.label='fig.wide'}
plot_grid(gg_beta, gg_beta_1, ncol = 2)
```

$\beta$ — вероятность ошибки II рода.

Считается, что допустимо $\beta \le 0.2$, но часто про нее забывают.

Если мы уменьшаем $\alpha$ (график справа), то возрастает $\beta$.

---

## Мощность теста — <br/>вероятность найти различия, если они есть

```{r echo = FALSE, purl = FALSE, opts.label='fig.wide'}
plot_grid(gg_power, gg_power_1, ncol = 2)
```

$Power = 1 - \beta$ — мощность теста.

Хорошо, когда мощность не меньше $0.8$.

Мощность теста зависит от величины наблюдаемого эффекта (от величины различий).

---

## С увеличением объема выборки <br/>растет мощность теста

```{r echo=FALSE, purl=FALSE, opts.label='fig.wide.taller'}
# Plots of power vs. sample size etc.
# Modified after http://imdevsoftware.wordpress.com/2013/01/17/255/

# Need pwr, reshape2, ggplot2 packages
gen_pwr_vs_n <- function(d = c(0.2, 0.5, 0.8), a = c(0.05, 0.01), n = 150){
  if(!require(pwr)){install.packages("pwr");library("pwr")}
  # t-TEST
  #---------------------------------
  n <- 1:n
  t.test.power.effect<-
    as.data.frame(do.call("cbind", lapply(1:length(d),function(i){
    sapply(1:length(a),function(k){
      sapply(1:length(n), function(j){
        #       paste(d[i], n[j], a[k])
        power.t.test(n = n[j],d = d[i],sig.level = a[k],power = NULL,
                     type = "two.sample")$power
      })
    })
  })))
  t.test.power.effect[is.na(t.test.power.effect)]<-0 # some powers couldn't be calculated, set these to zero
  # melt the data
  if(!require(reshape2)){install.packages("reshape2");library("reshape2")}
  measured <- length(d)*length(a)
  t.test.power.effect <- melt(t.test.power.effect, measure.vars = 1:measured)
  # fill the levels of n, a, and d
  nms <- expand.grid(size = n, sig.level = a, effect = d)
  t.test.power.effect <- cbind(t.test.power.effect, nms)
  # do-not need variable column
  t.test.power.effect <- t.test.power.effect[, -1]
  return(t.test.power.effect)
}

dat <-gen_pwr_vs_n(n = 150)
# factors
dat$sig.level <- factor(dat$sig.level, levels = c(0.01, 0.05),
                        labels = c("alpha == 0.01", "alpha == 0.05"))
dat$effect <- factor(dat$effect, levels = c(0.2, 0.5, 0.8),
                     labels = c("Слабый эффект", "Умеренный эффект", "Сильный эффект"))

# pwr_size <-
#   ggplot(data = dat[(dat$effect == "d = 0.5" & dat$sig.level == "p = 0.05"), ],
#          aes(x = size, y = value, color = sig.level)) +
#   geom_line(size = 1.5) +
#   scale_colour_discrete(name = "Уровень\nзначимости") +
#   labs(x = "Объем выборки", y = "Мощность") +
#   ggtitle("t-тест, d = 0.5") +
#   theme_minimal(base_size = 18) +
#   theme(legend.key = element_blank(),
#         axis.line = element_line(colour = "black"))
# pwr_size
#
# pwr_size_apha <- ggplot(data = dat[dat$effect == "d = 0.5", ],
#                         aes(x = size, y = value, color = sig.level)) +
#   geom_line(size = 1.5) +
#   scale_colour_discrete(name = "Уровень\nзначимости",
#                         limits = c("alpha == 0.05", "alpha == 0.01")) +
#   labs(x = "Объем выборки", y = "Мощность") +
#   ggtitle("t-тест, d = 0.5") +
#   theme(legend.key = element_blank(),
#         axis.line = element_line(colour = "black"))
# pwr_size_apha

pwr_size_alpha_d <- ggplot(data = dat, aes(x = size, y = value, color = sig.level)) +
    geom_line(size = 1) + facet_wrap(~effect) +
  scale_colour_manual(name = "Уровень\nзначимости",
                        limits = c("alpha == 0.05", "alpha == 0.01"), values = c('steelblue', 'red'), labels = c(bquote(alpha==0.05), bquote(alpha==0.01))) +
  labs(x = "Объем выборки", y = "Мощность") +
  scale_y_continuous(breaks = seq(0, 1, 0.2)) +
  geom_hline(yintercept = 0.8, linetype = 2) +
  ggtitle("Мощность двухвыборочного t-теста") +
  theme(legend.key = element_blank(),
        axis.line = element_line(colour = "black"))
pwr_size_alpha_d
```



class: middle, center, inverse

# Двухвыборочный t-тест

---

## Гипотезы в двухвыборочном $t$-тесте и тестовая статистика

$H_0: \mu_1 - \mu_2 = 0$ — средние значения не различаются в двух группах

$H_A: \mu_1 - \mu_2 \ne 0$ — средние значения различаются

<br/>

Т.е. нас интересует __разность выборочных средних__.

Ее ожидаемое значение при $H_0$ будет 0.


t-тест в общем виде выглядит так

$$t=\frac{\text{Наблюдаемая величина - Ожидаемое значение}}{\text{Стандартная ошибка}}$$
---

## t-тест и его разновидности

Двухвыборочный t-тест используется для проверки значимости различий между средними

$$t=\frac{(\bar{x}_1 - \bar{x}_2) - (\mu_1 - \mu_2)}{SE_{\bar{x}_1 - \bar{x}_2}} \; = \; \frac{\bar{x}_1 - \bar{x}_2}{SE_{\bar{x}_1 - \bar{x}_2}}$$

--

$SE_{\bar{x}_1 - \bar{x}_2}$ — стандартная ошибка разности двух средних, может рассчитываться по-разному

- t-тест Стьюдента — если считать, что дисперсии в группах равны
- t-тест Уэлча — если считать, что дисперсии могут быть разными

---

## Стандартная ошибка разности средних в t-тесте Стьюдента

Student 1908

Если группы независимы и дисперсии в них равны, то по центральной предельной теореме

$$SE_{\bar{x}_1 - \bar{x}_2} = \sqrt{ \frac{\sigma^2}{n_{1}} + \frac{\sigma^2}{n_{2}}} \approx \sqrt{ \frac{s^2}{n_{1}} + \frac{s^2}{n_{2}}}$$

$s^2 = \cfrac{(n_1 - 1)s^2_1 + (n_2 - 1)s^2_2}{n_1 + n_2 - 2}$ — это __обобщенная дисперсия__ по двум выборкам.

Результирующая $t$-статистика подчиняется $t$-распределению с  $df = n_1 + n_2 - 2$.

--

Осторожно, равенство дисперсий в группах —  
это часто нереалистичное предположение!

---

## Cтандартная ошибка разности средних в t-тесте Уэлча

Если группы независимы и дисперсии в них неизвестны, то получается

$$SE_{\bar{x}_1 - \bar{x}_2} = \sqrt{ \frac{\sigma^2_{1}}{n_{1}} + \frac{\sigma^2_{2}}{n_{2}}} \approx \sqrt{ \frac{s^2_{1}}{n_{1}} + \frac{s^2_{2}}{n_{2}}}$$

--

Проблема в том, что эта величина __лишь приблизительно следует t-распределению__, если считать его степени свободы как обычно для двух групп $df = n_1 + n_2 - 2$.

Это из-за того, что мы оцениваем __две__ дисперсии  
при помощи их стандартных отклонений. 

---

## Приблизительное число степеней свободы

Можно рассчитать по уравнению Уэлча-Саттеруэйта. Это решит проблему. 

$$df_{ Welch-Satterthwaite} \approx \cfrac {\bigg(\cfrac{s^2_{1}}{n_{1}} + \cfrac{s^2_{2}}{n_{2}}\bigg)^2}
{\cfrac{1}{n_{1} - 1}\bigg(\cfrac {s_{1}^2} {n_{1}}\bigg)^2 + \cfrac{1}{n_{2} - 1}\bigg(\cfrac {s_{2}^2} {n_{2}}\bigg)^2}$$


t-тестом Уэлча можно пользоваться, даже если дисперсии равны.

Он немного консервативнее, чем тест Стьюдента.

---

## Условия применимости двухвыборочного t-теста

Почти такие же, как условия справедливости ЦПТ

- Наблюдения независимы друг от друга.
- Выборки независимы друг от друга (новое условие).
- Объем выборки достаточно велик или величины нормально распределены.

---

class: middle, center, inverse

# Двухвыборочный t-тест в R

---

## Пример: Гормоны и артериальная гипертензия

Синдром Кушинга — это нарушения уровня артериального давления, вызванные гиперсекрецией кортизола надпочечниками.

В датасете `Cushings` (пакет `MASS`) записаны данные о секреции двух метаболитов при разных типах синдрома (данные из кн. Aitchison, Dunsmore, 1975).

- `Tetrahydrocortisone` — секреция тетрагидрокортизона с мочой (мг/сут.)
- `Pregnanetriol` — секреция прегнантриола с мочой (мг/сут.)
- `Type` — тип синдрома:
    - `a` — аденома
    - `b` — двусторонняя гиперплазия
    - `c` — карцинома
    - `u` — не известно

Давайте сравним секрецию тетрагидрокортизона при аденома и двусторонней гиперплазии надпочечников. Различается ли она?

---

## Открываем данные

```{r}
library(MASS)
data("Cushings")
```

Все ли правильно открылось?

```{r}
head(Cushings)
str(Cushings)
```

---

## Знакомимся с данными

Есть ли пропущенные значения?

```{r}
colSums(is.na(Cushings))
```

<br/>

Каковы объемы выборки в каждой группе?

```{r}
table(Cushings$Type)
```

Обратите внимание, объемы выборок **маленькие**.

---

## Проверяем условия применимости...

1.Наблюдения независимы друг от друга?

- Да, независимы. Это случайная выборка.

<br/>

2.Выборки независимы друг от друга?

- Да, независимы. В группах разные люди (естественно, т.к. тип синдрома у человека может быть только какой-то один).

<br/>

3.Объем выборки достаточно велик или величины нормально распределены?

- Объем выборки мал

```{r}
table(Cushings$Type)
```

Нужно проверить форму распределения в обеих группах.

---

## Нормально ли распределены концентрации тетрагидрокортизона в группах?

```{r eval=FALSE}
library(car)
qqPlot(Cushings$Tetrahydrocortisone[Cushings$Type == 'a'])
qqPlot(Cushings$Tetrahydrocortisone[Cushings$Type == 'b'])
```

```{r echo=FALSE, opts.label='fig.wide'}
library(car)
par(mfrow = c(1, 2))
qqPlot(Cushings$Tetrahydrocortisone[Cushings$Type == 'a'], id = FALSE)
qqPlot(Cushings$Tetrahydrocortisone[Cushings$Type == 'b'], id = FALSE)
par(mfrow = c(1, 1))
```

Удовлетворительно. При таких малых объемах выборки сложно ожидать лучшего. 

<!-- Будем считать, что можно аппроксимировать концентрацию тетрагидрокортизона нормальным распределением. -->

---

## Двухвыборочный t-тест в R: способ 1.

Сравним секрецию тетрагидрокортизона при помощи **двухвыборочного** t-теста.

```
t.test(x = значения_в_гр.1, 
       y = значения_в_гр.2)
```

```{r}
tt <- t.test(x = Cushings$Tetrahydrocortisone[Cushings$Type == 'a'],
             y = Cushings$Tetrahydrocortisone[Cushings$Type == 'b'])
tt
```

---

## Опишем результаты

```{r echo=FALSE}
tt
```

- Секреция тетрагидрокортизона значимо различается у пациентов с аденомой и двусторонней гиперплазией надпочечников ( $t_{`r round(tt$parameter, 2)`} = `r round(tt$statistic, 2)`$, $p = `r format.pval(tt$p.value, eps = 0.05)`$)


<br/>

Можно указать в скобках не сравнение с $\alpha$, а само значение $p$:  
( $t_{`r round(tt$parameter, 2)`} = `r round(tt$statistic, 2)`$, $p = `r format.pval(tt$p.value, digits = 2, eps = 0.001)`$).

Только не надо безумствовать и указывать слишком много знаков...

---

## Задание 3: Двухвыборочный t-тест в R, способ 2.

Перепишите вызов функции t.test с использованием другого шаблона вызова (с использованием формулы).

`t.test(formula = что_зависит ~ группы, data = данные)`

Второй вариант синтаксиса можно использовать только, если у вас есть только две группы. Если групп больше, то можно отфильтровать нужные с помощью логического вектора.

```
t.test(formula = что_зависит ~ группы, data = данные,
       subset = логический_вектор)
```

---

## Решение: Двухвыборочный t-тест в R, способ 2.

`t.test(formula = что_зависит ~ группы, data = данные)`

Второй вариант синтаксиса можно использовать только, если у вас есть только две группы. Если групп больше, то можно отфильтровать нужные с помощью логического вектора.

```
t.test(formula = что_зависит ~ группы, data = данные,
       subset = логический_вектор)
```

```{r eval=FALSE}
t.test(formula = Tetrahydrocortisone ~ Type, data = Cushings, 
       subset = Cushings$Type %in% c('a', 'b'))
```

Результаты точно такие же, естественно.

---

## Задание 4 

Посмотрите структуру результатов (`tt`) при помощи
функции `str()` и извлеките из них:

- степени свободы
- уровень значимости
- значение t-критерия

---

## Решение: Что спрятано в результатах?

Как называются отдельные элементы результатов можно узнать посмотрев их структуру при помощи функции `str()`

```{r}
str(tt)
```

---

## Решение: Можно получить элементы результатов в виде отдельных чисел

```{r purl=FALSE}
tt$parameter # степени свободы
tt$p.value # уровень значимости
tt$statistic # значение t-критерия
```

---

## График со средними и доверительными интервалами

```{r}
ggplot(data = Cushings[Cushings$Type %in% c('a', 'b'), ],
       aes(x = Type, y = Tetrahydrocortisone)) +
  stat_summary(fun.data = mean_cl_normal)
```

---

class: middle, center, inverse

# Двухвыборочный t-тест (самостоятельная работа)

---

## Задание 5

Файл `aml.csv` содержит данные о влиянии регулярной химиотерапии на продолжительность ремиссии.

Прочитаем эти данные
```{r}
rem <- read.csv(file = "data/aml.csv", header = TRUE)
head(rem)
```

- В переменной `time` представлена продолжительность ремиссии в днях.
- `group` указывает, к какой экспериментальной группе принадлежал пациент. В группе 1 проводилась регулярная химиотерапия, в группе 2 - нет.

Ваша задача сравнить эти группы с помощью t-теста.

---

## Решение: Разведочный анализ

```{r  purl=FALSE}
str(rem)
# Делаем group фактором
rem$group <- factor(rem$group, labels = c("therapy", "control"))

# Пропущенные значения?
colSums(is.na(rem))

# Объемы выборок?
table(rem$group)
```

---

## Решение: Проверка условий применимости

```{r  purl=FALSE}
# Выборки малы, поэтому проверяем на нормальность и отсутствие выбросов
op <- par(mfrow = c(1, 2))
qqPlot(rem$time[rem$group == "therapy"])
qqPlot(rem$time[rem$group == "control"])
par(op)
```

---

## Решение: Проверка условий применимости

Есть отскакивающее значение в группе `therapy`, в этой группе оно 11 по порядку (видно на `qqPlot()`).

```{r  purl=FALSE}
rem$time[rem$group == "therapy"]
rem$time[rem$group == "therapy"][11]
```

Пусть в этом случае это вполне реальное наблюдение, но это значение придется исключить, т.к. t-тест не устойчив к выбросам.

---

## Решение: Двухвыборочный t-тест

```{r purl=FALSE}
# удалено наблюдение со значением 161
tt <- t.test(formula = time ~ group, data = rem,
       subset = rem$time != 161)
```

Или то же самое:

```{r purl=FALSE, results="hide"}
# удалено 11 наблюдение в группе `therapy`
tt <- t.test(x = rem$time[rem$group == 'therapy'][-11],
       y = rem$time[rem$group == 'control'])
```

---

## Решение: Результаты двухвыборочного t-теста

```{r purl=FALSE}
tt
```

- `r ifelse(tt$p.value <= 0.05, 'Продолжительность ремиссии значимо различается', 'Не найдено значимых различий продолжительности ремиссии')` у пациентов после регулярной лучевой терапии и обычного лечения ( $t_{`r round(tt$parameter, 2)`} = `r round(tt$statistic, 2)`$, $p = `r format.pval(tt$p.value, eps = 0.01, digits = 3)`$).

---

## Решение: График со средними и доверительными интервалами

```{r }
ggplot(data = rem[rem$time != 161, ], aes(x = factor(group), y = time)) + 
  stat_summary(fun.data = mean_cl_normal)
```

---

class: middle, center, inverse

# Парный t-тест (факультативно)

---

## Пример: Снотворное

В датасете `sleep` содержатся данные об увеличении продолжительности сна по сравнению с контролем после применения двух снотворных препаратов (Cushny, Peebles, 1905, Student, 1908)

Одинаково ли два снотворных влияют на увеличение продолжительности сна?

```{r}
data(sleep)
head(sleep)
# str(sleep)
```

---

## Проверяем условия применимости...

1.Наблюдения независимы друг от друга?

- Да, независимы. Это случайная выборка людей.

2.Выборки независимы друг от друга?

- **Нет!**. В группах одни и те же люди (10 человек, каждый пил оба снотворных).  
**ОСТОРОЖНО**. Эти данные НЕ ПОДХОДЯТ для двухвыборочного t-теста, т.к. группы не являются взаимно независимыми. Нужно использовать **парный** t-тест.

<br/>

3.Объем выборки достаточно велик или величины нормально распределены?

- Объем выборки мал

```{r}
table(sleep$group)
```

Нужно проверить форму распределения в обеих группах.

---

## Нормально ли распределена зависимая переменная в группах?

```{r eval=FALSE}
qqPlot(sleep$extra[sleep$group == 1])
qqPlot(sleep$extra[sleep$group == 2])
```

```{r echo=FALSE}
par(mfrow = c(1, 2))
qqPlot(sleep$extra[sleep$group == 1], id = FALSE)
qqPlot(sleep$extra[sleep$group == 2], id = FALSE)
par(mfrow = c(1, 1))
```

Хорошо. Можно аппроксимировать нормальным распределением 

---

## Парный t-тест в R

Сравним увеличение продолжительности сна при помощи **парного** t-теста.

```{r}
t.test(formula = extra ~ group, data = sleep, paired = TRUE)
```

---

## Опишем результаты

```{r echo=FALSE}
tt <- t.test(formula = extra ~ group, data = sleep, paired = TRUE)
tt
```

- Различия изменения продолжительности сна при применении двух препаратов были достоверны ( $t_{`r round(tt$parameter, 2)`} = `r round(tt$statistic, 2)`$, $p = `r format.pval(tt$p.value, eps = 0.01)`$)

**Кстати, если бы мы не учли зависимость между группами, мы пришли бы к неверному выводу.**  В этом можно убедиться, выполнив этот код:

```{r eval=FALSE}
t.test(formula = extra ~ group, data = sleep)
```

---

## График со средними и доверительными интервалами

```{r }
ggplot(data = sleep, aes(x = factor(group), y = extra)) + 
  stat_summary(fun.data = mean_cl_normal)
```

---

## Take-home messages

- По центральной предельной теореме выборочные средние нормально распределены $$\bar X \sim N (\mu, \sigma / \sqrt{n})$$.
- Доверительный интервал к среднему значению можно построить из нормального распределения, если известна $\sigma$ в генеральной совокупности, или из $t$-распределения, если она не известна.
- При тестировании нулевой гипотезы оценивают вероятность получения данного или более экстремального значения тестовой статистики при условии, что $H_0$ справедлива. Если эта вероятность меньше выбранного критического уровня значимости, то нулевую гипотезу отвергают.
- Для сравнения выборочных средних лучше использовать t-критерий в модификации Уэлча, который учитывает, что дисперсии в группах могут быть разными.
- Средние в независимых выборках нужно сравнивать двухвыборочным t-тестом.
- Если выборки зависимы — нужно это учесть, поэтому для сравнения средних используется парный t-тест.

---

## Дополнительные ресурсы

- OpenIntro: Statistics
- Quinn, Keough, 2002
- Sokal, Rohlf, 1995
- Zar, 1999
