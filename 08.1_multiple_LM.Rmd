---
title: "Множественная регрессия"
author: Вадим Хайтов, Марина Варфоломеева
output:
  ioslides_presentation:
    widescreen: true
    css: assets/my_styles.css
    logo: assets/Linmod_logo.png
#   beamer_presentation:
#     colortheme: beaver
#     highlight: tango
#     includes:
#       in_header: ./includes/header.tex
#     pandoc_args:
#     - --latex-engine=xelatex
#     - -V fontsize=10pt
#     - -V lang=russian
#     slide_level: 2
#     theme: default
#     toc: no
editor_options:
  chunk_output_type: console
---

```{r setup, include = FALSE, cache = FALSE, purl = FALSE}
# output options
options(width = 70, scipen = 6, digits = 3)
library(knitr)
# chunk default options
opts_chunk$set(fig.align='center', tidy = FALSE, fig.width = 7, fig.height = 3, warning = FALSE, message = FALSE)
```

## Множественная регрессия



### Вы сможете

+ Подобрать модель множественной линейной регрессии
+ Протестировать ее статистическую значимость и валидность

## Пример: птицы в лесах Австралии

Фрагментация лесных местообитаний - одна из важнейших проблем Австралии.
От каких характеристик лесного участка зависит обилие птиц во фрагментированных лесных массивах? (Loyn, 1987)

<div class="columns-2">

![forest in Victoria, Australia](images/vict_m.jpg)
<small>Mystic Forest - Warburton, Victoria by ¡kuba! on flickr</small>

56 лесных участков:

- ABUND - обилие птиц
- AREA - площадь участка
- YRISOL - год изоляции участка
- DIST - расстояние до ближайшего леса
- LDIST - расстояние до ближайшего большого леса
- GRAZE - пастбищная нагрузка (1-5)
- ALT - высота над уровнем моря

</div>

<small>Пример из кн. Quinn, Keugh, 2002, данные из Loyn, 1987)</small>

## Читаем данные

```{r}
bird <- read.csv("data/loyn.csv")
```
Все ли правильно открылось?

```{r}
str(bird)
```

Есть ли пропущенные значения?

```{r}
colSums(is.na(bird))
```



## Можно ли ответить на вопрос таким методом?

```{r}
cor(bird)
```

>- Нет

>- Обычная корреляция не учитывает, что взаимосвязь между переменными может находиться под контролем других переменных и их взаимодействий.
>- Множественные тесты. При тестировании значимости множества коэффициентов корреляции нужно вводить поправку для уровня значимости. Лучше было бы учесть все в одном анализе.

## Нам предстоит построить модель множественной линейной регрессии

$$y_i = b_0 + b_1x_{1i} + b_2x_{2i} + b_3x_{3i} + ... + b_{p - 1}x_{p - 1\;i} + e_i$$

- $y_i$ --- значение зависимой переменной для $i$-того наблюдения
- $b_0$ --- свободный член (intercept). Значение $y$ при $x_1 = x_2 = x_3= \ldots = x_{p - 1} = 0$
- $b_1$ --- частный угловой коэффициент для зависимости $y$ от $x_1$. Показывает, на сколько единиц изменяется $y$ при изменении $x_1$ на одну единицу и при условии, что все остальные предикторы не изменяются
$b_2$, $b_3$, ...., $b_{p - 1}$ --- аналогично
- $e_i$ --- варьирование $y$, не объясненное данной моделью
- $p$ --- число параметров модели


## Геометрическая интерпретация множественной линейной модели 

### Для случая с одним предиктором $y_i = b_0 + b_1x_{1i} + \varepsilon_i$ --- линия регрессии

```{r, echo=FALSE, purl=FALSE}
library(ggplot2)
dfr <- data.frame(x1 = runif(25, 0, 10))
dfr$y1 <- 5 + 5 * dfr$x1 + rnorm(25, 0, 5)
ggplot(data = dfr, aes(x = x1, y = y1)) + geom_point() + geom_smooth(method = "lm") + ylab("y")
```

## Геометрическая интерпретация множественной линейной модели

### Для случая с двумя предикторами $y_i = b_0 + b_1x_{1i} + b_2x_{2i} + \varepsilon_i$ --- плоскость в трехмерном пространстве

```{r, echo=FALSE, fig.height=5, fig.width=5, purl=FALSE}
library(plot3D)

dfr$x2 <- runif(25, 10, 20)
dfr$y2 <- 5 + 5 * dfr$x1 + 3 * dfr$x2 + rnorm(25, 0, 15)
fit <- lm(y2 ~ x1 + x2, data = dfr)

# predict values on regular xy grid
x1.pred <- seq(0, 10, length.out = 20)
x2.pred <- seq(10, 20, length.out = 20)
xy <- expand.grid(x1 = x1.pred, 
                  x2 = x2.pred)

y2.pred <- matrix(nrow = 20, ncol = 20, 
                  data = predict(fit, newdata = xy, 
                                 interval = "prediction"))

# fitted points for droplines to surface
fitpoints <- predict(fit) 

scatter3D(x = dfr$x1, y = dfr$x2, z = dfr$y2, 
          pch = 18, cex = 1.5,
          theta = 30, phi = 16,
          ticktype = "detailed",
          surf = list(x = x1.pred, y = x2.pred, z = y2.pred,
                      facets = NA, fit = fitpoints),
          xlab = "First predictor X1", ylab = "Second predictor X2",
          zlab = "Response variable",
          main = "")
```

## Геометрическая интерпретация множественной линейной модели

### Для случая с большим количеством предикторов 

$$y_i = b_0 + b_1x_{1i} + b_2x_{2i} + b_3x_{3i} + ... + b_{p - 1}x_{p - 1\;i} + \varepsilon_i$$

Плоскость в n-мерном пространстве, оси которого образованы значениями предикторов



# Протокол анализа данных  


## Тяжелая жизнь статистического аналитика

Аналитик, строящий модель, должен быть уверен в том,  
что он не построит колосса на глиняных ногах.

Главный принцип --- "garbage in, garbage out".


## Откуда ждать удара?

Сбор данных часто проходит по принципу "ДДПР" ("Давай-давай, потом разберемся"), аналитик может не знать подводных камней сбора материала, но он должен их выявить. 

Данные могут не отвечать многочисленным ограничениям регрессионного анализа.

Характер данных и связей между ними может требовать доработки данных (преобразования, стандартизации и т.п.). 

Но! Самое главное гипотеза должна быть сформулирована до начала анализа, точнее, до начала сбора материала.


## Как справится со сложностями?

Часть осмысления данных необходимо провести до построения модели (разведочный анализ).

Часть --- после того как модель построена (анализ валидности модели).


Давайте подробнее рассмотрим тактику анализа данных.

## 1. Дизайн сбора материала

Прежде всего, нужно осмыслить дизайн сбора материала, чтобы понять являются ли отдельные наблюдения взаимно-независимыми.

- Нет ли скрытых группирующих (случайных) факторов
- Нет ли временных и пространственных автокорреляций 


## 2. Влиятельные наблюдания

Нужно проверить, нет ли отскакивающих значений.

Такие значения иногда могут быть следствием ошибки в исходных данных.




## 3. Распределение зависимой переменной

Простая линейная регрессия часто не подходит для моделирования некоторых величин (например для счетных данных). 

## 4. Характер связи между зависимой переменной и предикторами

Связь между откликом и предикторами может выглядеть нелинейной.

Если выявляются нелинейные зависимости, то нужно правильно выбрать тип модели.

Не все зависимости можно моделировать с помощью простых регрессионных моделей.   

## 5. Независимость предикторов

Нужно проверить, нет ли взаимозависимости (коллинеарности) между предикторами.

О том, почему это важно и как это проверять, поговорим позже.

## 6. Моделирование

Строим модель, соответствующую нашей гипотезе.


## 7. Проверка валидности модели

Для моделей с нормальным распределением отклика:

1. Независимы ли наблюдения друг от друга (проверяем еще раз, т.к. речь идет уже не о дизайне, а о модели).
2. Присутствует ли гетерогенность дисперсии  
3. Соответствует ли распределение остатков модели нормальному распределению

Если нарушений условий применимости не выявлено, то можно начать осмыслять результаты построения модели.

Если выявлены нарушения условий применимости, то надо задуматься о том, верно ли подобран тип модели и все ли хорошо с данными. Возвращаемся к пункту 1.


# Разведочный анализ данных 


## Знакомство с данными {.smaller}

```{r fig.height=5, fig.width=10}
library(car)
pairs(bird)
```

## Итог предварительного знакомства с данными

- Большая часть значений  AREA, DIST, LDISТ сгруппирована в начале области определения. Связь между AREA и откликом выглядит нелинейной. Нужно логарифмировать эти переменные.

- Переменная GRAZE --- это уровень выпаса скота __в баллах__, ее лучше было бы анализировать как дискретную переменную. Технически, ее можно анализировать и как непрерывную, но нужно помнить, это предполагает одинаковые различия между разными соседними уровнями выпаса скота. Это нереалистично.


Трансформируем переменные

```{r}
bird$logAREA <- log(bird$AREA)
bird$logDIST <- log(bird$DIST)
bird$logLDIST <- log(bird$LDIST)
```

## Ищем отскоки

__Отскоки (выбросы, outliers)__ - наблюдения, которые имеют более высокие (или низкие) значения относительно большинства других наблюдений.

## Ищем отскоки: точечные диаграммы Кливленда {.columns-2 .smaller}


```{r fig.width=5}
ggplot(bird, aes(y = 1:nrow(bird), x = ABUND)) + 
  geom_point() + 
  labs(y = 'Порядковый номер \nв датасете', 
       x = 'Значения переменной')
```


## Ищем отскоки: точечные диаграммы Кливленда {.columns-2 .smaller}


```{r fig.width=4}
ggplot(bird, aes(y = 1:nrow(bird), x = AREA)) + 
  geom_point() + 
  labs(y = 'Порядковый номер \nв датасете', 
       x = 'Значения переменной')
```



```{r fig.width=4}
ggplot(bird, aes(y = 1:nrow(bird), x = logAREA)) + 
  geom_point() + 
  labs(y = 'Порядковый номер \nв датасете', 
       x = 'Значения переменной')
```



## Ищем отскоки: диаграммы Кливленда для всех переменных


```{r gg-arrange, echo=FALSE, fig.height=5}
gg_dot <- ggplot(bird, aes(y = 1:nrow(bird))) + geom_point() + ylab('index')
Pl1 <- gg_dot + aes(x = ABUND)
Pl2 <- gg_dot + aes(x = YRISOL)
Pl3 <- gg_dot + aes(x = logAREA)
Pl4 <- gg_dot + aes(x = logDIST)
Pl5 <- gg_dot + aes(x = logLDIST)
Pl6 <- gg_dot + aes(x = ALT)
Pl7 <- gg_dot + aes(x = GRAZE)

library(cowplot) # пакет для группировки графиков
theme_set(theme_bw())
plot_grid(Pl1, Pl2, Pl3, Pl4, Pl5, Pl6, 
          Pl7, ncol = 3, nrow = 3)
```


## Ищем отскоки: диаграммы Кливленда для всех переменных

Код для  графика

```{r gg-arrange, echo=TRUE, eval=FALSE, purl=TRUE}
```



## Проблемы: сильные корреляции между некоторыми предикторами

```{r fig.height=6, fig.width=10, echo=FALSE}
pairs(bird[, c("ABUND", "logAREA", "YRISOL", "logDIST", "logLDIST", "GRAZE", "ALT")])
```


## Модель, которую мы хотим подобрать

$$\begin{aligned}{ABUND}_i &= b_0 + b_1 \cdot logAREA_i + b_2 \cdot YRISOL_i + \\
&+ b_3 \cdot logDIST_i + b_4 \cdot logLDIST_i + b_5 \cdot GRAZE_i + b_6 \cdot ALT_i + \varepsilon_i\\
\end{aligned}$$

Возможно, что эту модель придется изменить.

В начале нам нужно убедиться, что условия применимости линейной регрессии выполняются.

## Вспомним условия применимости линейной регрессии

- Линейная связь между зависимой переменной ($Y$) и предикторами ($X$)
- Независимость значений $Y$ друг от друга
- Нормальное распределение $Y$ для каждого уровня значений $X$
- Гомогенность дисперсий $Y$ для каждого уровня значений $X$
- __Отсутствие коллинеарности предикторов (для можественной регрессии)__

# Мультиколлинеарность

## Мультиколлинеарность

Мультиколлинеарность ---  наличие линейной зависимости между независимыми переменными (предикторами) в регрессионной модели.

При наличии мультиколлинеарности оценки параметров неточны, а значит сложно интерпретировать влияние предикторов на отклик.

### Косвенные признаки мультиколлинеарности:

- Большие ошибки оценок параметров     
- Большинство значений параметров модели незначимо отличается от нуля, но F критерий говорит, что модель в целом значима.

### Проверка на мультиколлинеарность

- Коэффициент раздутия дисперсии (Variance inflation factor, VIF).

## Как рассчитывается VIF

Пусть наша модель $y_i = b_0 + b_1 x_{1i} + b_2 x_{2i} + \ldots + b_{p - 1} x_{p - 1\;i} + \varepsilon_i$.

Нужно оценить какую долю изменчивости конкретного предиктора могут объяснить другие предикторы (т.е. насколько предикторы независимы).

Для каждого предиктора:

1. Строим регрессионную модель данного предиктора от всех остальных:
$$x_1 = c_0 + c_1x_2 +c_2x_3 + .... + c_{p - 2}x_{p - 1}$$
2. Находим $R^2$ этой модели.
3. Вычисляем коэффициент раздутия дисперсии:
$$VIF = \frac{1}{1-R^2}$$

## Мультиколлинеарность опасна

В случае наличия мультиколлинеарности:

- Оценки коэффициентов модели нестабильны (даже могут менять знак при небольших
изменениях модели или исходных данных).
- Стандартные ошибки оценок параметров увеличатся в $\sqrt{VIF}$ раз.
- В результате меньше шансов заметить влияние предиктора, т.к. уровень значимости (p-value) в тестах будет выше.


## Как бороться с мультиколлинеарностью?

- Можно последовательно удалить из модели избыточные предикторы с VIF > 2  
    1. подбираем модель
    2. считаем VIF
    3. удаляем предиктор с самым большим VIF
    4. повторяем 1-3

- Можно заменить исходные предикторы новыми независимыми друг от друга переменными, сконструированными методом главных компонент (Principal component analysis, PCA).

## Задание

- Постройте множественную линейную регрессию для зависимости обилия птиц (`ABUND`) от других переменных (`logAREA`, `YRISOL`, `logDIST`, `logLDIST`, `GRAZE`, `ALT`)

$$\begin{aligned}{ABUND}_i &= b_0 + b_1 \cdot logAREA_i + b_2 \cdot YRISOL_i + \\
&+ b_3 \cdot logDIST_i + b_4 \cdot logLDIST_i + b_5 \cdot GRAZE_i + b_6 \cdot ALT_i + \varepsilon_i\\
\end{aligned}$$

- Используйте функцию `vif()`, чтобы проверить, коллинеарны ли предикторы.

Дополните код:

```{r eval=FALSE, purl=TRUE}
mod1 <- lm(formula = , data = )
vif()
```

## Решение

```{r}
# Строим модель
mod1 <- lm(formula = ABUND ~  logAREA + YRISOL + logDIST + logLDIST + GRAZE + ALT, 
           data = bird)
# Проверяем, есть ли коллинеарность?
vif(mod1)
```

В нашей модели сильной мультиколлинеарности нет.

Однако, возможно `GRAZE` --- избыточный предиктор.

## Удалим из модели избыточный предиктор

```{r}
mod2 <- update(mod1, . ~ . -GRAZE)
vif(mod2)
```

Теперь мультиколлинеарности нет. В модели осталось пять предикторов (и шесть параметров).


$$\begin{aligned}{ABUND}_i &= b_0 + b_1 \cdot logAREA_i + b_2 \cdot YRISOL_i + \\
&+ b_3 \cdot logDIST_i + b_4 \cdot logLDIST_i + b_5 \cdot ALT_i + e_i\\
\end{aligned}$$

## Уравнение модели

$$\begin{aligned}{ABUND}_i &= b_0 + b_1 \cdot logAREA_i + b_2 \cdot YRISOL_i + \\
&+ b_3 \cdot logDIST_i + b_4 \cdot logLDIST_i + b_5 \cdot ALT_i + e_i\\
\end{aligned}$$

Мы подобрали коэффициенты и можем записать уравнение модели.

```{r}
coef(mod2)
```

$$\begin{aligned}{ABUND}_i &= -226.00 + 3.69 \cdot logAREA_i + 0.12 \cdot YRISOL_i - \\
&-0.10 \cdot logDIST_i -0.33 \cdot logLDIST_i + 0.03 \cdot ALT_i + e_i\\
\end{aligned}$$

>- Дайте трактовку этим коэффициентам

## Множественная регрессия в матричном виде

Аналогично простой регрессии

$$
\mathbf{Y} = \mathbf{Xb} + \mathbf{e}
$$

Отличие лишь в форме модельной матрицы

## Модельная матрица в множественной регрессии

```{r}
X <- model.matrix(mod2)

head(X)
```





## В этой модели многие предикторы незначимы {.smaller}

```{r}
summary(mod2)
```

## Дальше может быть два варианта действий:

- Оставить все как есть. Если значение коэффициента при предикторе не значимо отличается от нуля, значит, этот предиктор не влияет на обилие птиц.
- Провести пошаговый подбор оптимальной модели (Об этом на следующей лекции).

Сейчас оставим все как есть.

Теперь давайте проверим, выполняются ли оставшиеся условия применимости, а после этого попытаемся выяснить, какие предикторы влияют сильнее всего.

## Задание

Проверьте, выполняются ли условия применимости для модели `mod2`. Дополните код:

```{r eval=FALSE, purl=TRUE}
library()
mod2_diag <- data.frame(fortify(), $GRAZE)
# 1) График расстояния Кука
ggplot(data = , aes(x = 1:, y = .cooksd)) + geom_bar(stat = "")
# 2) График остатков от предсказанных значений
gg_resid <- ggplot(data = , aes(x = , y = )) + geom_point() + geom_hline()
gg_resid
# 3) Графики остатков от предикторов в модели и нет
res_1 <- gg_resid + aes(x = logAREA)
res_1
res_2 <- gg_resid
res_3 <- gg_resid
res_4 <- gg_resid
res_5 <- gg_resid
res_6 <- gg_resid
# все графики вместе
library(gridExtra)
grid.arrange(res_1, res_2, nrow = 2)
# 4) Квантильный график остатков
library(car)
qq
```

## Решение

### 1) График расстояния Кука 

- Выбросов нет

```{r solution-0a, fig.show='hold', purl=FALSE, fig.width=10, fig.height=2.2}
library(ggplot2)
mod2_diag <- data.frame(fortify(mod2), GRAZE = bird$GRAZE)

ggplot(data = mod2_diag, aes(x = 1:nrow(mod2_diag), y = .cooksd)) + 
  geom_bar(stat = "identity")
```

## Решение

### 2) График остатков от предсказанных значений

- Выбросов нет
- Гетерогенность дисперсии?
- Два наблюдения с очень большими предсказанными значениями и большими остатками. Хорошо бы проверить их.

```{r solution-1a, fig.show='hold', purl=FALSE, fig.width=10, fig.height=2.2}
gg_resid <- ggplot(data = mod2_diag, aes(x = .fitted, y = .stdresid)) + 
  geom_point() + geom_hline(yintercept = 0)
gg_resid
```


## Решение

### 3) Графики остатков от предикторов в модели и нет

- Величина остатков зависит от уровня выпаса скота. Возможно, не стоило удалять эту переменную
- Есть наблюдения с экстремальными значениями предикторов (два больших леса, один далекий, один высокогорный).  Хорошо бы проверить их.
```{r solution-2a, fig.show='hold', purl=FALSE, fig.width=10, fig.height=5, echo=FALSE}
res_1 <- gg_resid + aes(x = logAREA)
res_2 <- gg_resid + aes(x = YRISOL)
res_3 <- gg_resid + aes(x = logDIST)
res_4 <- gg_resid + aes(x = logLDIST)
res_5 <- gg_resid + aes(x = GRAZE)
res_6 <- gg_resid + aes(x = ALT)

library(gridExtra)
grid.arrange(res_1, res_2, res_3, res_4,
             res_5, res_6, nrow = 2)
```

## Решение

### 3) Код для графиков остатков от предикторов в модели и нет

```{r solution-2a, fig.show='hide', purl=FALSE, echo=TRUE}
```

## Решение

### 4) Квантильный график остатков

- Отклонения от нормального распределения остатков незначительны

```{r solution-3a, purl=FALSE, fig.width=4, fig.height=4, message=FALSE}
library(car)
qqPlot(mod2)
```

# Сравнение силы влияния разных предикторов --- стандартизованные коэффициенты

## Какой из предикторов оказывает наиболее сильное влияние? {.smaller}

```{r}
coef(summary(mod2))
```

## Какой из предикторов оказывает наиболее сильное влияние?

Для ответа на этот вопрос надо "уравнять" шкалы, всех предикторов, то есть стандартизовать их. 

Коэффициенты при стандартизованных предикторах покажут, насколько сильно меняется отклик __при изменении предиктора на одно стандартное отклонение__.

Для стандартизации используем функцию `scale()`

```{r}
mod2_scaled <- lm(ABUND ~ scale(logAREA) + scale(YRISOL) + scale(logDIST) + 
                          scale(logLDIST) + scale(ALT), data = bird)
```

## Какой из предиктов оказывает наиболее сильное влияние на обилие птиц?

```{r}
coef(summary(mod2_scaled))
```

>- Сильнее всего на обилие птиц влияют логарифм площади леса и продолжительность изоляции
>- При изменении логарифма площади на 1 стандартное отклонение, обилие птиц изменяется на `r round(coef(mod2_scaled)[2], 2)`
>- При изменении продолжительности изоляции на 1 стандартное отклонение, обилие птиц изменяется на `r round(coef(mod2_scaled)[3], 2)`

# График предсказаний модели множественной линейной регрессии

## График предсказаний модели множественной линейной регрессии

Для простой линейной регрессии легко нарисовать график на плоскости, поскольку есть только две переменные: отклик и предиктор.

Во множественной линейной регрессии один отклик, но предикторов много, поэтому чтобы изобразить на плоскости нужны ухищрения.

Самое частое решение --- построить график $y$ от наиболее важного предиктора при средних значениях всех остальных предикторов. Но можно рассмотреть и любые другие интересные вам сценарии.

## Выбираем предикторы для графика модели

$$\begin{aligned}\widehat{ABUND}_i = &-226.00 + 3.69 \cdot logAREA_i + 0.12 \cdot YRISOL_i \\
&- 0.10 \cdot logDIST_i - 0.33 \cdot logLDIST_i + 0.03 \cdot ALT_i\\
\end{aligned}$$

<br/>

```{r}
coef(mod2_scaled)
```

Судя по стандартизованным коэффициентам, самая важная здесь переменная --- это логарифм площади леса.

Построим график предсказанных значений обилия птиц для лесов разной площади при средних значениях всех остальных предикторов.


## График предсказаний модели "как есть"


$$\begin{aligned}\widehat{ABUND}_i = &-226.00 + 3.69 \cdot logAREA_i + 0.12 \cdot YRISOL_i \\
&- 0.10 \cdot logDIST_i - 0.33 \cdot logLDIST_i + 0.03 \cdot ALT_i\\
\end{aligned}$$

В нашей модели предикторы трансформированы и ABUND от них зависит линейно.

```{r gg-predict-data, echo=FALSE}
# Искусственный датафрейм для предсказаний
MyData <- data.frame(
  logAREA = seq(min(bird$logAREA), max(bird$logAREA), length.out = 100),
  YRISOL = mean(bird$YRISOL),
  logDIST = mean(bird$logDIST),
  logLDIST = mean(bird$logLDIST),
  ALT = mean(bird$ALT))
# Предсказанные значения
Predictions <- predict(mod2, newdata = MyData,  interval = 'confidence')
MyData <- data.frame(MyData, Predictions)
# График предсказаний модели
Pl_predict <- ggplot(MyData, aes(x = logAREA, y = fit)) +
  geom_ribbon(alpha = 0.2, aes(ymin = lwr, ymax = upr)) +
  geom_line()
Pl_predict
```

## График предсказаний модели "как есть"

```{r gg-predict-data, echo=TRUE, purl=FALSE, eval=FALSE}
```

## График предсказаний модели после обратной трансформации предикторов

$$\begin{aligned}\widehat{ABUND}_i = &-226.00 + 3.69 \cdot logAREA_i + 0.12 \cdot YRISOL_i \\
&- 0.10 \cdot logDIST_i - 0.33 \cdot logLDIST_i + 0.03 \cdot ALT_i\\
\end{aligned}$$

Для удобства восприятия лучше сделать обратную трансформацию предикторов.

```{r gg-predict, echo=FALSE}
# Обратная трансформация предиктора, который будем изображать
MyData$AREA <- exp(MyData$logAREA)
# График предсказаний модели
Pl_predict <- ggplot(MyData, aes(x = AREA, y = fit)) +
  geom_ribbon(alpha = 0.2, aes(ymin = lwr, ymax = upr)) +
  geom_line() + xlab("Площадь леса") + ylab("Обилие птиц")
Pl_predict
```

## График предсказаний модели после обратной трансформации предикторов

```{r gg-predict, echo=TRUE, purl=FALSE, eval=FALSE}
```

## Вопрос:

Имеет ли смысл на таком графике изображать исходные наблюдения?

>- Обычно это делают, чтобы (1) посмотреть на величину остатков, (2) посмотреть на диапазон исходных наблюдений.

```{r purl=FALSE, echo=FALSE, fig.height=3}
Pl_predict +
  geom_point(data = bird, aes(x = AREA, y = ABUND))
```

>- Нет, нет смысла. Наш график показывает предсказания только для определенных наблюдений --- со средними значениями нескольких предикторов. Если мы нарисуем значения наблюдений, то их остатки не будут иметь смысл, т.к. у этих наблюдений в реальности совсем не обязательно средние значения этих предикторов.

## Описание множественной линейной регрессии

- Записываем уравнение модели. 
- Общую значимость модели оцениваем при помощи _F_-критерия. 
- Качество подгонки модели описываем при помощи коэффициента детерминации с поправкой ($R^2_{adj.}$).
- При обсуждении значимости отдельных предикторов можно привести таблицу с оценками коэффициентов и тестами их значимости. 
- При сравнении влияния отдельных предикторов приводим стандартизованные коэффициенты
- Приводим график предсказаний модели




## Take-home messages

- При построении множественной регрессии важно, помимо других условий, проверить модель на наличие мультиколлинеарности
- Если модель построена на основе стандартизированных значений предикторов, то можно сравнивать влияние этих предикторов

## Что почитать

+ Гланц, С., 1998. Медико-биологическая статистика. М., Практика
+ Кабаков Р.И. R в действии. Анализ и визуализация данных на языке R. М.: ДМК Пресс, 2014
+ Diez, D.M., Barr, C.D. and Çetinkaya-Rundel, M., 2015. OpenIntro Statistics. OpenIntro.
+ Zuur, A., Ieno, E.N. and Smith, G.M., 2007. Analyzing ecological data. Springer Science & Business Media.
+ Quinn G.P., Keough M.J. 2002. Experimental design and data analysis for biologists
+ Logan M. 2010. Biostatistical Design and Analysis Using R. A Practical Guide
