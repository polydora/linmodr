---
title: "Линейные модели с дискретными предикторами"
subtitle: "Линейные модели..."
author: "Марина Варфоломеева, Вадим Хайтов"
institute: "Кафедра Зоологии беспозвоночных, Биологический факультет, СПбГУ"
fontsize: 10pt
classoption: 't,xcolor=table'
language: russian, english
output:
  beamer_presentation:
    theme: default
    toc: no
    colortheme: beaver
    latex_engine: xelatex
    slide_level: 2
    fig_crop: false
    highlight: tango
    includes:
      in_header: ./includes/header.tex
---

```{r setup, include = FALSE, cache = FALSE, purl = FALSE}
options(width = 80, scipen = 4)
library(knitr)
# chunk default options
opts_chunk$set(fig.show='hold', size='footnotesize', comment="#", warning=FALSE, message=FALSE, dev='cairo_pdf', fig.height=2.5, fig.width=7.7)
# library("extrafont")
source("support_linmodr.R")
```

## Линейные модели с дискретными предикторами (дисперсионный анализ)

### Вы сможете

- Объяснить, в чем опасность множественных сравнений, и как с ними можно бороться
- Рассказать, как в дисперсионном анализе моделируются значения зависимой переменной
- Интерпретировать и описать результаты, записанные в таблице дисперсионного анализа
- Перечислить и проверить условия применимости дисперсионного анализа
- Провести множественные попарные сравнения при помощи post hoc теста Тьюки, представить и описать их результаты
- Построить график результатов дисперсионного анализа

## Дисперсионный анализ (Analysis Of Variance, ANOVA)

__Дисперсионный анализ в широком смысле__ --- анализ изменений непрерывной зависимой переменной в связи с разными источниками изменчивости (предикторами). 

Мы использовали его для тестирования значимости предикторов в линейных моделях.

__Дисперсионный анализ в узком смысле__ --- это частный случай, когда в линейной модели используются только дискретные предикторы (факторы). 

Он используется для сравнения средних значений зависимой переменной в дискретных группах, заданных факторами..

## Пример: яйца кукушек

Различаются ли размеры яиц кукушек в гнездах разных птиц-хозяев?

Датасет `cuckoos` из пакета `DAAG`:

- `species`  --- вид птиц-хозяев (фактор)
- `length` --- длина яиц кукушек в гнездах хозяев (зависимая переменная)

\vskip0pt plus 1filll
\tiny Данные: Latter, 1902; источник: Tippett, 1931


## Открываем данные

```{r, data-eggs}
library(DAAG)
data("cuckoos")
# Положим данные в переменную с коротким названием, чтобы меньше печатать
eggs <- cuckoos
head(eggs, 3)
# Сократим названия переменных
colnames(eggs) <- c('len', 'br', 'sp', 'id')
```


## Изменим названия уровней фактора, чтобы было легче понять о каких птицах речь

```{r, tidy=FALSE}
levels(eggs$sp)
levels(eggs$sp) <- c("ЛесЗав", "ЛугКон", "БелТряс", 
                        "Малин", "ЛесКон", "Крапив")
```

## Исследуем данные

```{r}
# Пропущенных значений нет
colSums(is.na(eggs))

# Данные не сбалансированы (размеры групп разные)
table(eggs$sp)
```


## Задание

Дополните код, чтобы построить график зависимости размера яиц кукушек (`len`) от вида птиц-хозяев (`sp`), в гнездах которых были обнаружены яйца. На графике должны быть изображены средние значения и их 95% доверительные интервалы, а цвет должен соответствовать виду птиц-хозяев.

```{r eval=FALSE}
theme_set( )
ggplot(data = , aes()) + 
  stat_summary(geom = "pointrange", fun.data = mean_cl_normal)
```

```{r gg-mean-conf-limit, echo=FALSE, purl=FALSE}
library(ggplot2)
theme_set(theme_bw())
ggplot(data = eggs, aes(x = sp, y = len, colour = sp)) + 
  stat_summary(geom = "pointrange", fun.data = mean_cl_normal)
```

## Решение

```{r gg-mean-conf-limit, echo=TRUE, purl=FALSE}
```

## "Некрасивый" порядок уровней на графике

На этом графике некрасивый порядок уровней: средние для разных уровней фактора `eggs$sp` расположены, как кажется, хаотично.

Порядок групп на графике определяется порядком уровней фактора.

```{r purl=FALSE}
# "старый" порядок уровней
levels(eggs$sp)
```

```{r gg-mean-conf-limit, echo=FALSE, purl=FALSE}
```

## Меняем порядок уровней

Давайте изменим порядок уровней в факторе `eggs$sp` так, чтобы он соответствовал возрастанию средних значений длины яиц `eggs$len`.

```{r}
# "старый" порядок уровней
levels(eggs$sp)
# переставляем уровни в порядке следования средних значений 
eggs$sp <- reorder(eggs$sp, eggs$len, FUN = mean)
# "новый" порядок уровней стал таким
levels(eggs$sp)
```

## График с новым порядком уровней

С новым порядком уровней нам легче визуально сравнивать друг с другом категории.

Поскольку, изменив порядок уровней, мы внесли изменения в исходные данные, придется полностью обновить график (т.к.`ggplot()` хранит данные внутри графика).

```{r}
ggplot(data = eggs, aes(x = sp, y = len, colour = sp)) + 
  stat_summary(geom = "pointrange", fun.data = mean_cl_normal)
```

## Понравившийся график, если понадобится, можно в любой момент довести до ума, а остальные удалить

```{r gg-mean-conf-limit-coloured-labs, purl=FALSE}
ggplot(data = eggs, aes(x = sp, y = len, colour = sp)) + 
  stat_summary(geom = "pointrange", fun.data = mean_cl_normal) +
  labs(x = "Вид хозяев", y = "Длина яиц кукушек, мм") + 
  scale_colour_brewer(name = "Вид \nхозяев", palette = "Dark2") + 
  scale_x_discrete(labels = c("Крапивник", "Луговой\nконек", "Малиновка",
"Белая\nтрясогузка", "Лесной\nконек", "Лесная\nзавирушка")) + 
  theme(legend.position = "none")
```

# Множественные сравнения

## Множественные сравнения

Мы могли бы сравнить длину яиц в гнездах резных хозяев при помощи t-критерия. У нас всего 6 групп. Сколько возможно между ними попарных сравнений?

```{r gg-mean-conf-limit-coloured-labs, echo=FALSE, purl=FALSE}
```

\pause

Всего возможно 15 сравнений.

Если для каждого сравнения вероятность ошибки первого рода будет $\alpha_{per\ comparison} = 0.05$, то для группы из 15 сравнений --- ?

\pause

Если предположить, что сравнения независимы (это не так), то $\alpha_{family\ wise} = 1 - (1 - 0.05) ^ {15} = 0.54$. Мы рискуем найти различия там где их нет с 54% вероятностью!

Для зависимых сравнений вероятность будет немного меньше, но все равно значительно больше $0.05$

## Поправка Бонферрони --- очень жесткий способ коррекции.

Если нужно много сравнений, можно снизить $\alpha _{per\ comparison}$ до общепринятого уровня

$$\alpha _{per\ comparison} = \frac{\alpha _{family\ wise}}{n}$$

\vfill
\pause

Например, если хотим зафиксировать $\alpha _{family\ wise} = 0.05$

С поправкой Бонферрони $\alpha _{per\ comparison} = 0.05 / 15 = 0.003$

Это очень жесткая поправка! Мы рискуем не найти достоверных различий, даже там, где они есть...

Но есть выход. Вместо множества попарных сравнений можно использовать один тест --- дисперсионный анализ (analysis of variation, ANOVA).

\vskip0pt plus 1filll

# Линейные модели с дискретными предикторами

## Для кодирования дискретных факторов в R используются две параметризации

\columnsbegin
\column{0.5\textwidth}
__Параметризация индикаторных переменных__ (dummy coding, treatment parametrization, reference cell model) в R обозначается __contr.treatment__.

С ней вы уже знакомы. Используется по умолчанию в R.

\column{0.5\textwidth}

__Параметризация эффектов__ (effects coding, sum-to-zero  parameterization) в R обозначается __contr.sum__.

"Классическая" параметризация для дисперсионного анализа. Нужна, если хочется использовать т.наз. III тип сумм квадратов в многофакторном дисперсионном анализе со взаимодействием факторов.

\columnsend

# Параметризация индикаторных переменных

## Переменные-индикаторы

<!-- \begin{adjustbox}{max width=\textwidth} -->
\begin{tabular}{p{1.1cm}|C{1.3cm} C{1.3cm} C{1.3cm} C{1.3cm} C{1.3cm}}
\textbf{Фактор} & \multicolumn{5}{c}{\textbf{Переменные-индикаторы}} \\
\cline{2-6}
\texttt{sp} &\texttt{spЛугКон} \newline $x_1$ &  \texttt{spМалин} \newline $x_2$ & \texttt{spБелТряс} \newline $x_3$ & \texttt{spЛесКон} \newline $x_4$ & \texttt{spЛесЗав} \newline $x_5$\\
\hline
Крапив   &  0 &  0  & 0 & 0 & 0 \\
ЛугКон   &  1 &  0  & 0 & 0 & 0 \\
Малин    &  0 &  1  & 0 & 0 & 0 \\
БелТряс  &  0 &  0  & 1 & 0 & 0 \\
ЛесКон   &  0 &  0  & 0 & 1 & 0 \\
ЛесЗав   &  0 &  0  & 0 & 0 & 1 \\
\end{tabular}
<!-- \end{adjustbox} -->

Переменных-индикаторов всегда на одну меньше, чем число уровней фактора.

Уровень "`r levels(eggs$sp)[1]`" будет базовым: для его кодирования не\ нужна отдельная переменная.


## Уравнение модели в параметризации индикаторов

<!-- \begin{adjustbox}{max width=\textwidth} -->
\begin{tabular}{p{1.1cm}|C{1.3cm} C{1.3cm} C{1.3cm} C{1.3cm} C{1.3cm}}
\textbf{Фактор} & \multicolumn{5}{c}{\textbf{Переменные-индикаторы}} \\
\cline{2-6}
\texttt{sp} &\texttt{spЛугКон} \newline $x_1$ &  \texttt{spМалин} \newline $x_2$ & \texttt{spБелТряс} \newline $x_3$ & \texttt{spЛесКон} \newline $x_4$ & \texttt{spЛесЗав} \newline $x_5$\\
\hline
Крапив   &  0 &  0  & 0 & 0 & 0 \\
ЛугКон   &  1 &  0  & 0 & 0 & 0 \\
Малин    &  0 &  1  & 0 & 0 & 0 \\
БелТряс  &  0 &  0  & 1 & 0 & 0 \\
ЛесКон   &  0 &  0  & 0 & 1 & 0 \\
ЛесЗав   &  0 &  0  & 0 & 0 & 1 \\
\end{tabular}
<!-- \end{adjustbox} -->

$$y _{i} = b_0 + b_1 x _{1i} + \ldots + b_5 x_{5i} + e_{i}$$

- $b_0$ --- это среднее значение отклика для базового уровня фактора.
- $b_1, ..., b_5$ --- это отклонения от базового уровня для средних с другими уровнями фактора.


## Коэффициенты модели в параметризации индикаторов

<!-- \begin{adjustbox}{max width=\textwidth} -->
\begin{tabular}{p{1.1cm}|C{1.3cm} C{1.3cm} C{1.3cm} C{1.3cm} C{1.3cm}}
\textbf{Фактор} & \multicolumn{5}{c}{\textbf{Переменные-индикаторы}} \\
\cline{2-6}
\texttt{sp} &\texttt{spЛугКон} \newline $x_1$ &  \texttt{spМалин} \newline $x_2$ & \texttt{spБелТряс} \newline $x_3$ & \texttt{spЛесКон} \newline $x_4$ & \texttt{spЛесЗав} \newline $x_5$\\
\hline
Крапив   &  0 &  0  & 0 & 0 & 0 \\
ЛугКон   &  1 &  0  & 0 & 0 & 0 \\
Малин    &  0 &  1  & 0 & 0 & 0 \\
БелТряс  &  0 &  0  & 1 & 0 & 0 \\
ЛесКон   &  0 &  0  & 0 & 1 & 0 \\
ЛесЗав   &  0 &  0  & 0 & 0 & 1 \\
\end{tabular}
<!-- \end{adjustbox} -->

```{r}
mod_treatment <- lm(len ~ sp, data = eggs)
round(coef(mod_treatment), 2)
```

## Уравнение модели в параметризации индикаторов

<!-- \begin{adjustbox}{max width=\textwidth} -->
\begin{tabular}{p{1.1cm}|C{1.3cm} C{1.3cm} C{1.3cm} C{1.3cm} C{1.3cm}}
\textbf{Фактор} & \multicolumn{5}{c}{\textbf{Переменные-индикаторы}} \\
\cline{2-6}
\texttt{sp} &\texttt{spЛугКон} \newline $x_1$ &  \texttt{spМалин} \newline $x_2$ & \texttt{spБелТряс} \newline $x_3$ & \texttt{spЛесКон} \newline $x_4$ & \texttt{spЛесЗав} \newline $x_5$\\
\hline
Крапив   &  0 &  0  & 0 & 0 & 0 \\
ЛугКон   &  1 &  0  & 0 & 0 & 0 \\
Малин    &  0 &  1  & 0 & 0 & 0 \\
БелТряс  &  0 &  0  & 1 & 0 & 0 \\
ЛесКон   &  0 &  0  & 0 & 1 & 0 \\
ЛесЗав   &  0 &  0  & 0 & 0 & 1 \\
\end{tabular}
<!-- \end{adjustbox} -->

```{r purl=FALSE}
round(coef(mod_treatment), 2)
```
```{r echo=FALSE}
cf <- round(coef(mod_treatment), 2)
```

$$\widehat{len}_i = 21.12 + 1.17 sp_{\text{ЛугКон}\ i} + 1.44 sp_{\text{Малин}\ i} + 1.77 sp_{\text{БелТряс}\ i} + 1.96 sp_{\text{ЛесКон}\ i} + 1.99 sp_{\text{ЛесЗав}\ i}$$

## Уравнение модели в параметризации индикаторов


```{r purl=FALSE}
round(coef(mod_treatment), 2)
```
```{r echo=FALSE}
cf <- round(coef(mod_treatment), 2)
```

$$\widehat{len}_i = 21.12 + 1.17 sp_{\text{ЛугКон}\ i} + 1.44 sp_{\text{Малин}\ i} + 1.77 sp_{\text{БелТряс}\ i} + 1.96 sp_{\text{ЛесКон}\ i} + 1.99 sp_{\text{ЛесЗав}\ i}$$

Первый коэффициент --- средний размер яиц кукушек в гнездах крапивников (на базовом уровне):

- $\widehat{len}_{\text{Крапив}\ i} = `r cf[1]`$

Другие коэффициенты --- разница размеров яиц кукушек в гнездах других хозяев и в гнездах крапивников (отклонения от базового уровня):

- $\widehat{len}_{\text{ЛугКон}\ i} = 21.12 + 1.17 sp_{\text{ЛугКон}\ i} = `r sum(cf[1:2])`$
- $\widehat{len}_i = 21.12 + 1.44 sp_{\text{Малин}\ i} = `r sum(cf[c(1, 3)])`$
- $\widehat{len}_i = 21.12 + 1.77 sp_{\text{БелТряс}\ i} = `r sum(cf[c(1, 4)])`$
- $\widehat{len}_i = 21.12 + 1.96 sp_{\text{ЛесКон}\ i} = `r sum(cf[c(1, 5)])`$
- $\widehat{len}_i = 21.12 + 1.99 sp_{\text{ЛесЗав}\ i} = `r sum(cf[c(1, 6)])`$



# Параметризация эффектов

## Переменные-эффекты

<!-- \begin{adjustbox}{max width=\textwidth} -->
\begin{tabular}{p{1.1cm}|C{0.6cm} C{0.6cm} C{0.6cm} C{0.6cm} C{0.6cm}}
\textbf{Фактор} & \multicolumn{5}{c}{\textbf{Переменные-эффекты}} \\
\cline{2-6}
\texttt{sp} &\texttt{sp1} \newline $x_1$ &  \texttt{sp2} \newline $x_2$ & \texttt{sp3} \newline $x_3$ & \texttt{sp4} \newline $x_4$ & \texttt{sp5} \newline $x_5$\\
\hline
Крапив   &  1 &  0  &  0 &  0 &  0 \\
ЛугКон   &  0 &  1  &  0 &  0 &  0 \\
Малин    &  0 &  0  &  1 &  0 &  0 \\
БелТряс  &  0 &  0  &  0 &  1 &  0 \\
ЛесКон   &  0 &  0  &  0 &  0 &  1 \\
ЛесЗав   & -1 & -1  & -1 & -1 & -1 \\
\end{tabular}
<!-- \end{adjustbox} -->


Переменных-эффектов всегда на одну меньше, чем число уровней фактора.

Переменные закодированы при помощи -1, 0 и 1 (сумма кодов для возможных состояний одной переменной равна нулю).

Для последней группы все переменные-эффекты будут равны $-1$.


## Уравнение модели в параметризации эффектов


<!-- \begin{adjustbox}{max width=\textwidth} -->
\begin{tabular}{p{1.1cm}|C{0.6cm} C{0.6cm} C{0.6cm} C{0.6cm} C{0.6cm}}
\textbf{Фактор} & \multicolumn{5}{c}{\textbf{Переменные-эффекты}} \\
\cline{2-6}
\texttt{sp} &\texttt{sp1} \newline $x_1$ &  \texttt{sp2} \newline $x_2$ & \texttt{sp3} \newline $x_3$ & \texttt{sp4} \newline $x_4$ & \texttt{sp5} \newline $x_5$\\
\hline
Крапив   &  1 &  0  &  0 &  0 &  0 \\
ЛугКон   &  0 &  1  &  0 &  0 &  0 \\
Малин    &  0 &  0  &  1 &  0 &  0 \\
БелТряс  &  0 &  0  &  0 &  1 &  0 \\
ЛесКон   &  0 &  0  &  0 &  0 &  1 \\
ЛесЗав   & -1 & -1  & -1 & -1 & -1 \\
\end{tabular}
<!-- \end{adjustbox} -->


$$y _{i} = b_0 + b_1 x _{1i} + \ldots + b_5 x_{5i} + e_{i}$$

- $b_0$ --- это общее среднее значение отклика.
- $b_1, ..., b_5$ --- это отклонения от общего среднего для средних с другими уровнями фактора, кроме последнего.
- для последнего уровня фактора отклонения от общего среднего --- это коэффициенты $b_1, ..., b_5$, взятые с противоположным знаком.


## Коэффициенты модели в параметризации эффектов

<!-- \begin{adjustbox}{max width=\textwidth} -->
\begin{tabular}{p{1.1cm}|C{0.6cm} C{0.6cm} C{0.6cm} C{0.6cm} C{0.6cm}}
\textbf{Фактор} & \multicolumn{5}{c}{\textbf{Переменные-эффекты}} \\
\cline{2-6}
\texttt{sp} &\texttt{sp1} \newline $x_1$ &  \texttt{sp2} \newline $x_2$ & \texttt{sp3} \newline $x_3$ & \texttt{sp4} \newline $x_4$ & \texttt{sp5} \newline $x_5$\\
\hline
Крапив   &  1 &  0  &  0 &  0 &  0 \\
ЛугКон   &  0 &  1  &  0 &  0 &  0 \\
Малин    &  0 &  0  &  1 &  0 &  0 \\
БелТряс  &  0 &  0  &  0 &  1 &  0 \\
ЛесКон   &  0 &  0  &  0 &  0 &  1 \\
ЛесЗав   & -1 & -1  & -1 & -1 & -1 \\
\end{tabular}
<!-- \end{adjustbox} -->

```{r}
mod_sum <- lm(len ~ sp, data = eggs, contrasts = list(sp = contr.sum))
round(coef(mod_sum), 2)
```

\vspace{\baselineskip}

Коэффициенты моделей будут разными в разных параметризациях, но предсказания будут совершенно одинаковыми.

## Уравнение линейной модели в параметризации эффектов

<!-- \begin{adjustbox}{max width=\textwidth} -->
\begin{tabular}{p{1.1cm}|C{0.6cm} C{0.6cm} C{0.6cm} C{0.6cm} C{0.6cm}}
\textbf{Фактор} & \multicolumn{5}{c}{\textbf{Переменные-эффекты}} \\
\cline{2-6}
\texttt{sp} &\texttt{sp1} \newline $x_1$ &  \texttt{sp2} \newline $x_2$ & \texttt{sp3} \newline $x_3$ & \texttt{sp4} \newline $x_4$ & \texttt{sp5} \newline $x_5$\\
\hline
Крапив   &  1 &  0  &  0 &  0 &  0 \\
ЛугКон   &  0 &  1  &  0 &  0 &  0 \\
Малин    &  0 &  0  &  1 &  0 &  0 \\
БелТряс  &  0 &  0  &  0 &  1 &  0 \\
ЛесКон   &  0 &  0  &  0 &  0 &  1 \\
ЛесЗав   & -1 & -1  & -1 & -1 & -1 \\
\end{tabular}
<!-- \end{adjustbox} -->

```{r purl=FALSE}
round(coef(mod_sum), 2)
```
```{r echo=FALSE}
cf <- round(coef(mod_sum), 2)
```

$$\widehat{len}_i = 22.51 -1.39 sp_{1\ i} -0.22 sp_{2\ i} + 0.05 sp_{3\ i} + 0.38 sp_{4\ i} + 0.57 sp_{5\ i}$$

## Уравнение линейной модели в параметризации эффектов

```{r purl=FALSE}
round(coef(mod_sum), 2)
```
```{r echo=FALSE}
cf <- round(coef(mod_sum), 2)
```

$$\widehat{len}_i = 22.51 -1.39 sp_{1\ i} -0.22 sp_{2\ i} + 0.05 sp_{3\ i} + 0.38 sp_{4\ i} + 0.57 sp_{5\ i}$$

Первый коэффициент --- средний размер яиц кукушек по всем данным:

- $\overline{len} = `r cf[1]`$

Другие коэффициенты --- отличие размеров яиц в гнездах хозяев от общего среднего.

Для всех хозяев, кроме последнего, эти отличия будут взяты со знаком "+":

- $\widehat{len}_{\text{Крапив}\ i} = 22.51 -1.39 sp_{1\ i} = `r sum(cf[1:2])`$
- $\widehat{len}_{\text{ЛугКон}\ i} = 22.51 -0.22 sp_{2\ i} = `r sum(cf[c(1, 3)])`$
- $\widehat{len}_{\text{Малин}\ i} = 22.51 + 0.05 sp_{3\ i} = `r sum(cf[c(1, 4)])`$
- $\widehat{len}_{\text{БелТряс}\ i} = 22.51 + 0.38 sp_{4\ i} = `r sum(cf[c(1, 5)])`$
- $\widehat{len}_{\text{ЛесКон}\ i} = 22.51 + 0.57 sp_{5\ i} = `r sum(cf[c(1, 6)])`$

Для последнего уровня фактора отличия будут взяты со знаком "-", т.к. все переменные-эффекты будут принимать значение -1:

- $\widehat{len}_{\text{ЛесЗав}\ i} = 22.51 -1.39 sp_{1\ i} -0.22 sp_{2\ i} + 0.05 sp_{3\ i} + 0.38 sp_{4\ i} + 0.57 sp_{5\ i} = `r cf[1] + sum(-cf[2:6])`$

# t-тесты значимости коэффициентов

## t-тесты значимости коэффициентов не информативны \newline в моделях с дискретными предикторами

\small

- Для модели __в параметризации индикаторов__ t-тесты коэффициентов показывают значимость отличий средних в группах от среднего на базовом уровне. 
- По значениям коэффициентов нельзя сказать влияет ли дискретный фактор целиком (исключение --- фактор с двумя градациями).

```{r}
coef(summary(mod_treatment))
```

\vspace{0.5\baselineskip}

- Для модели __в параметризации эффектов__ t-тесты коэффициентов показывают значимость отличий средних в группах от общего среднего -- это сравнение редко имеет смысл.

```{r}
coef(summary(mod_sum))
```

\normalsize

# Дисперсионный анализ

```{r echo=FALSE, purl=FALSE}
library(dplyr)
dat_smr <- eggs %>% group_by(sp) %>% summarise(mean = mean(len)) 
dat <- merge(eggs, dat_smr)
dat$sp <- as.numeric(dat$sp) + runif(nrow(dat), -0.15, 0.15)
d_lev <- levels(eggs$sp)
dat_smr$sp <- as.numeric(dat_smr$sp)

lims <- range(eggs$len) + 0.15 * c(-1, 1)
yannot <- lims[1] + 0.5
set.seed(83)
gmean <- mean(eggs$len, na.rm = TRUE)

# 35
id <- 9
Y <- dat$len[id]
Y_hat <-dat$mean[id]
X <- dat$sp[id]



pl <- ggplot(data = dat, aes(x = sp, y = len)) + theme(legend.position = 'none', axis.text.x = element_text(angle = 30, vjust = .8, hjust = .8)) + ylim(lims[1], lims[2]) + scale_x_continuous(breaks = 1:6, labels = d_lev)

# # Общая изменчивость (отклонения от общего среднего)
pl_tot <- pl + 
  geom_segment(aes(xend = sp, yend = gmean), colour = 'grey70', size = 0.75) +
  geom_hline(yintercept = gmean) + 
  geom_point(size = 1) +
  # annotate('text', label = 'SS[t] == sum((bar(y) - y[i]))^2', parse = TRUE, x = 6,  y = yannot, hjust = 1, size = 6) +
  ggtitle('Общая изм-ть')
# pl_tot

pl_all <- pl + 
  geom_segment(aes(xend = sp, yend = gmean), colour = 'grey70') +
  geom_point(data = dat_smr, aes(y = mean), size = 19, shape = 95, colour = 'dodgerblue1') + 
  geom_hline(yintercept = gmean) + 
  # annotate('segment', x = X, y = Y, xend = X, yend = gmean, colour = 'grey70', size = 1.75) + 
  annotate('segment', x = X, y = Y, xend = X, yend = Y_hat, colour = '#009E73', size = 1.75) +
  annotate('segment', x = X, y = Y_hat, xend = X, yend = gmean, colour = '#E69F00', size = 1.75) +
  geom_point(size = 1) +
  annotate('text', label = 'Общее\nсреднее', 
           x = 0,  y = gmean, hjust = -0.1, size = 4)
# pl_all
pl_no <- pl + 
  geom_hline(yintercept = gmean, linetype = 'dashed') + 
  geom_point(data = dat_smr, y = gmean, size = 19, shape = 95, colour = 'dodgerblue1') +
  annotate('segment', x = X, y = Y, xend = X, yend = gmean, colour = 'grey70') + 
  annotate('segment', x = X + 0.02, y = Y, xend = X + 0.02, yend = gmean, colour = '#009E73') +
  geom_point(size = 1) +
  annotate('text', label = 'Общее\nсреднее', 
           x = 0,  y = gmean, hjust = -0.1, size = 4)
# pl_no

# library(plyr)
# Межгрупповая изменчивость (связанная с фактором)
pl_x <- pl + 
  geom_hline(aes(yintercept = gmean)) + 
  geom_segment(data = dat_smr, aes(x = sp, y = mean, xend = sp, yend = gmean), colour = '#E69F00', size = 0.75) +
  geom_point(data = dat_smr, aes(y = mean), size = 19, shape = 95, colour = 'dodgerblue1') + 
  geom_point(size = 1) +
  # annotate('text', label = 'SS[x] == sum((bar(y) - hat(y)[i]))^2', parse = TRUE, x = 6,  y = yannot, hjust = 1, size = 6) +
  ggtitle('Факторная изм-ть')
# pl_x
# Внутригрупповая изменчивость (случайная)
pl_res <- pl + 
  geom_segment(data = dat, aes(xend = sp, yend = mean), colour = '#009E73', size = 0.75) +
  # geom_hline(yintercept = gmean, linetype = 'dashed') + 
  geom_point(data = dat_smr, aes(y = mean), size = 19, shape = 95, colour = 'dodgerblue1') + 
  geom_point(size = 1) +
  # annotate('text', label = 'SS[e] == sum(sum((y [i] - hat(y)[i])))^2', parse = TRUE, x = 6,  y = yannot, hjust = 1, size = 6) +
  ggtitle('Случайная изм-ть')  + theme(axis.title.y = element_blank())
# pl_res
```

## Общая изменчивость

```{r gg-tot, echo=FALSE, fig.height=3.5, purl=FALSE}
pl_tot +  annotate('text', label = 'Общее\nсреднее', 
           x = -0.5,  y = gmean, hjust = -0.1, size = 4)
```

Общая изменчивость SS~t~ --- это сумма квадратов отклонений наблюдаемых значений $y_i$ от общего среднего $\bar y$

## Факторная (межгрупповая) изменчивость


```{r echo=FALSE, fig.height=3.5, purl=FALSE}
pl_x +  annotate('text', label = 'Общее\nсреднее', 
           x = -0.5,  y = gmean, hjust = -0.1, size = 4)
```

Отклонения внутригрупповых средних от общего среднего в генеральной совокупности --- это эффект фактора $\alpha_j = \mu_j - \mu$, где $j = 1, 2, ..., p$ --- это одна из $p$ групп. 

Мы оцениваем эффект фактора по реальным данным $\bar{y}_j-\bar{y}$

## Структура общей изменчивости

\centering
$SS_t = SS_x + SS_e$

\columnsbegin
\column{0.33\textwidth}

```{r echo=FALSE, fig.width=1.7*1.5, out.width='1.7in'}
pl_tot + annotate('text', label = 'Общее\nсреднее', 
           x = -1,  y = gmean, hjust = -0.1, size = 4)
```
\centering

$SS_{t}= \sum\sum{(\bar{y}-y_{ij})^2}$  
$df_{t} = n - 1$  
\column{0.31\textwidth}

```{r echo=FALSE, fig.width=1.6*1.5, out.width='1.6in'}
pl_x  + theme(axis.title.y = element_blank())
```
\centering

$SS_{x}=\sum{n_j(\bar{y}_j-\bar{y})^2}$  
$df_{x} = p - 1$  

\column{0.31\textwidth}

```{r echo=FALSE, fig.width=1.6*1.5, out.width='1.6in'}
pl_res
```
\centering

$SS_{e}= \sum\sum{(\bar{y}_{j}-y_{ij})^2}$  
$df_{e} = n - p$
\columnsend


## От изменчивостей к дисперсиям

\centering
$SS_t = SS_x + SS_e$ \qquad $MS_t \ne MS_x + MS_e$

\columnsbegin
\column{0.33\textwidth}

```{r echo=FALSE, fig.width=1.7*1.5, out.width='1.7in'}
pl_tot + annotate('text', label = 'Общее\nсреднее', 
           x = -1,  y = gmean, hjust = -0.1, size = 4)
```
\centering

$SS_{t}= \sum\sum{(\bar{y}-y_{ij})^2}$  
$df_{t} = n - 1$  

$MS_{t} = \frac {SS_{t}}{df_{t}}$

\column{0.31\textwidth}

```{r echo=FALSE, fig.width=1.6*1.5, out.width='1.6in'}
pl_x + theme(axis.title.y = element_blank())
```
\centering

$SS_{x}=\sum{n_j(\bar{y}_j-\bar{y})^2}$  
$df_{x} = p - 1$  

$MS_{x} = \frac {SS_{x}}{df_{x}}$

\column{0.31\textwidth}

```{r echo=FALSE, fig.width=1.6*1.5, out.width='1.6in'}
pl_res
```
\centering

$SS_{e}= \sum\sum{(\bar{y}_j-y_{ij})^2}$  
$df_{e} = n - p$

$MS_{e} = \frac{SS_{e}}{df_{e}}$

\columnsend

\note{
Они не зависят от числа наблюдений в выборке, в отличие от $SSx$ и $SS_e$
С их помощью можно проверить гипотезу о наличии связи между предиктором и откликом
}


## $MS_x$ и $MS_e$ помогают тестировать значимость фактора

Если дисперсии остатков в группах равны и фактор имеет фиксированное число градаций:

$E(MS_x) = \sigma^2 +  \sum n_i \frac{(\mu_i - \mu)^2}{p - 1} = \sigma^2 +  \sigma^2_x$

$E(MS_e) = \sigma^2$

\pause

Если зависимости нет, то $\mu_1 = \ldots = \mu_p$ --- средние равны во всех $p$ группах, и тогда $MS_x \sim MS_e$.

\pause

- $H_0: \mu_1 = \ldots = \mu_p$ --- средние во всех $p$ группах равны.
- $H_A: \exists\; i, j: \mu_i \ne \mu_j$ --- __хотя бы одно__ среднее отличается от общего среднего.

$$ F_{df_x, df_e} = \frac{MS _{x}}{MS_{e}}$$

## Тестирование значимости фактора при помощи F-критерия

$$ F_{df_x, df_e} = \frac{MS _{x}}{MS_{e}}$$

В однофакторном дисперсионном анализе $df_{x} = p - 1$ и $df_{e} = n - p$.

```{r f-distribution, echo=FALSE, purl=FALSE, fig.width=7, fig.height=2}
library(car)
df_1 <- 5
df_2 <- 114
F_val <- Anova(mod_treatment)[1, 3]
F_crit <- qf(p = 0.05, df1 = df_1, df2 = df_2, lower.tail = F)

dfr <- data.frame(f = seq(-0.3, 11, 0.01))
ggplot(dfr, aes(x = f)) + 
  stat_function(fun = df, args = list(df1 = df_1, df2 = 114), size = 1.3) + 
  geom_hline(yintercept = 0) +
  geom_vline(xintercept = qf(p = 0.95, df1 = df_1, df2 = 114), color = "red", linetype = "dashed") + 
  annotate("text", label = "F при α = 0.05", x = qf(p = 0.95, df1 = df_1, df2 = 114), y = 1, hjust = 1.1) +
  geom_vline(xintercept = F_val, linetype = "dashed") +
  annotate("text", label = "F", x = F_val, y = 1, hjust = -1) +
  labs(title = paste0("F-распределение, df1 = ", df_1, ", df2 = ", df_2), x = "F", y = "Плотность вероятности") + theme_bw(base_size = 10) + ylim(0, 1.1)
```


## Результаты дисперсионного анализа часто представляют в\ виде таблицы

<!-- \begin{adjustbox}{max width=\textwidth} -->
\begin{tabular}{L{2.2cm} cccc}
\textbf{Источник \linebreak[2] изменчивости}  & \textbf{SS} & \textbf{df} & \textbf{MS} & \textbf{F}  \\
\hline
Название фактора & $SS_{x}=\sum{n_j(\bar{y}_j-\bar{y})^2}$ & $df _x = p - 1$ & $MS _x = \frac{SS _x}{df _x}$ & $F _{df _x df _e} = \frac{MS _x}{MS _e}$ \\
Случайная & $SS_{e}= \sum\sum{(\bar{y}_j-y_{ij})^2}$ & $df _e = n - p$ & $MS _e = \frac{SS _e}{df _e}$ & \\
Общая & $SS_{t}= \sum\sum{(\bar{y}-y_{ij})^2}$ & $df _t = n - 1$ & & \\
\end{tabular}
<!-- \end{adjustbox} -->


Минимальное описание результатов в тексте должно содержать $F _{df _x, df _e}$ и $p$.


## Делаем дисперсионный анализ в R

В R есть много функций для дисперсионного анализа. Мы рекомендуем `Anova()` (__с большой буквы__) из пакета `car`. Зачем? Эта функция умеет тестировать влияние факторов в определенном порядке. Когда факторов будет больше одного, это станет важно для результатов.

```{r, message=FALSE}
library(car)
eggs_anova <- Anova(mod_treatment)
eggs_anova
```

## Результаты дисперсионного анализа

- Можно описать в тексте:

```{r, echo=FALSE}
result <- eggs_anova
dfs <- paste0(result$Df, collapse= ",")
fval <- round(result$'F value'[1], 2)
sign <- ifelse(result$'Pr(>F)'[1] <= 0.01, "$p < 0.01$", ifelse(result$'Pr(>F)'[1] <= 0.05, "$p < 0.05$", ""))
```

Длина яиц кукушек в гнездах разных птиц-хозяев значимо различается \newline ($F _{`r dfs`} = `r fval`$, `r sign`).

\vspace{2\baselineskip}

- Можно представить в виде таблицы:

\vspace{\baselineskip}

Длина яиц кукушек значимо различалась в гнездах разных птиц-хозяев (Табл. 1).

```{r echo=FALSE, results='asis', purl=FALSE}
library(xtable)
smr <- fix_Anova(eggs_anova,
                 rown = c("Хозяин", "Остаточная"), 
                 coln = c("SS", "df", "F", "P"))
xtb <- xtable(
  smr,
  caption = "Табл. 1. Результаты дисперсионного анализа длины яиц кукушек в гнездах разных птиц-хозяев. SS --- суммы квадратов отклонений, df --- число степеней свободы, F --- значение F-критерия, P --- уровень значимости.",
  label = "tab:oneanova")
print.xtable(xtb, comment = F, caption.placement = "top")
```

# Условия примененимости дисперсионного анализа

## Результатам тестов можно верить, если выполняются условия применимости

Условия применимости дисперсионного анализа:

- Случайность и независимость  наблюдений внутри групп
- Нормальное распределение остатков
- Гомогенность дисперсий остатков
- Отсутствие коллинеарности факторов (независимость групп)

### Другие ограничения:

- Лучше работает, если размеры групп примерно одинаковы (т.наз. сбалансированный дисперсионный комплекс)
- Устойчив к отклонениям от нормального распределения (при равных объемах групп или при больших выборках)

## Проверяем выполнение условий применимости

```{r}
# Данные для графиков остатков
mod_diag <- fortify(mod_treatment)
```
### 1) График расстояния Кука

```{r}
ggplot(mod_diag, aes(x = 1:nrow(mod_diag), y = .cooksd)) +
  geom_bar(stat = "identity")
```

- Выбросов нет

## 2) График остатков от предсказанных значений

```{r eval=FALSE, purl=FALSE}
ggplot(mod_diag, aes(x = .fitted, y = .stdresid)) + geom_jitter()
```

У нас один единственный дискретный предиктор, поэтому удобнее сразу боксплот


### 3) Графики остатков от предикторов в модели и не в модели

```{r}
ggplot(mod_diag, aes(x = sp, y = .stdresid)) + geom_boxplot()
```
- Дисперсии почти одинаковые. Может быть, в одной из групп чуть больше

## 4) Квантильный график остатков
```{r fig.width=3.5*2, out.width='3.5in', fig.height=2.3*2, out.height='2.3in'}
library(car)
qqPlot(mod_treatment, id = FALSE)
```

- Распределение остатков немного отличается от нормального

# Пост хок тесты

## Как понять, какие именно группы различаются

Дисперсионный анализ говорит нам только, есть ли влияние фактора, но не говорит, какие именно группы различаются.

Коэффициенты линейной модели в `summary(mod_treatment)` содержат лишь часть ответа --- сравнение средних значених всех групп со средним на базовом уровне.

Если нас интересуют другие возможные попарные сравнения, нужно сделать пост хок тест.

## Есть два способа понять, какие именно группы различаются

\columnsbegin
\column{0.49\textwidth}

\centering{\textbf{Линейные контрасты} (linear contrasts)}

- Гипотезы о межгрупповых различиях тестируются при помощи комбинаций из коэффициентов линейной модели.
- Набор гипотез (и сравнений) должен быть определен заранее.
- Делать можно вне зависимости от результатов дисперсионного анализа.

Этот способ за рамками курса.

\column{0.49\textwidth}

\centering\textbf{Post hoc тесты}

- Сравниваются все возможные группы.
- Нет четких заранее сформулированных гипотез.
- Делать можно, только если влияние соответствующего фактора оказалось значимым.

Этот способ мы обсудим.

\columnsend

## Разновидности пост хок тестов

Тесты без поправки на число сравнений:

- Наименьшая значимая разница Фишера (Fisher's Least Significant Difference)

Тесты с поправкой для уровня значимости $\alpha$:

- Поправка Бонферрони (Bonferroni correction)
- Поправка Сидака (Sidak's correction)
  
Тесты, основанные на распределении стьюдентизированного размаха:

- Тест Тьюки (Tuckey's Honest Significant Difference, HSD)
- Тест Стьюдента-Ньюмена-Кьюлса (Student-Newman-Kewls test, SNK)
- Тест Даннета (Dunnet's test) --- используется для сравнения с контрольной группой.

Тесты, основанные на F-тестах:

- Критерий Дункана (Dunkan's test)
- Тест Шеффе (Scheffe's test)

## Наименьшая значимая разница Фишера \newline Fisher's Least Significant Difference

Используется t-критерий с $df = df_e = n - p$:

\vspace{-1\baselineskip}

$$t = \frac{\bar{y}_i - \bar{y}_j}{\sqrt{MS_e \large(\frac{1}{n_i} + \frac{1}{n_j}\large)}}$$

- Подразумевается равенство дисперсий в сравниваемых группах

- Не вносится поправка для уровня значимости, учитывающая множественность сравнений. (Считается, что тест "защищен" от ошибок I рода, т.к. выполняется после того, как в ANOVA была отвергнута гипотеза о равенстве всех внутригрупповых средних).

__Осторожно!__ Этот тест слишком мягок, высока вероятность появления ошибок II рода (т.е. тест находит различия там, где их нет).

## После ANOVA часто приходится сравнивать несколько групп

Фактор в дисперсионном анализе может задавать больше двух групп. (Например, фактор вид птицы-хозяина в нашем примере).

На самом деле _t_-распределение не годится для случая, когда приходится сравнивать больше, чем две группы одновременно.

Вспомните, _t_-распределение --- это распределение стандартизованной разницы \newline средних значений __из\ двух выборок__, взятых из одной генеральной совокупности.


\vspace{2\baselineskip}

Нужен способ описать более сложное распределение --- для любого числа выборок.

## Три выборки

Представьте, что мы берем из одной и той же генеральной совокупности три выборки.

Средние значения $\bar y_1$, $\bar y_2$ и $\bar y_3$ в каждой из этих выборок скорее всего окажутся разными и не будут похожи на генеральное среднее $\mu$.

Как оценить, какой может быть эта разница? Нужно построить распределение. Но какое?

\pause

\vspace{6\baselineskip}

1. Возьмем $m$ выборок из одной генеральной совокупности

2. Отсортируем выборочные средние: $\bar y_{1} \ge \bar y_2 \ge \ldots \ge \bar y_{m}$

Это можно записать как $\bar y_{max} \ge \bar y_2 \ge \ldots \ge \bar y_{min}$

3. Вычислим разницу максимального и минимального средних $\bar y_{max} - \bar y_{min}$  

Если повторить 1--3 много раз, то получится распределение, которое показывает, чему может быть равна разница средних значений в выборках из одной генеральной совокупности. 

Такое распределение можно построить для любого числа выборок $m$.


## Распределение стьюдентизированного размаха \newline Studentized range distribution

Это распределение стандартизованной разницы минимального и\ максимального средних __для\ любого числа выборок__ из\ одной генеральной совокупности (форма зависит от\ $df$ и\ от\ числа выборок $m$).


```{r echo=FALSE, purl=FALSE}
# https://en.wikipedia.org/wiki/Studentized_range_distribution
# https://commons.wikimedia.org/wiki/File:StudentizedRangePDF.svg
dtukey <- function(q, nmeans, df) {
    delta = 0.001
    return (ptukey(q+delta, nmeans, df) - ptukey(q, nmeans, df)) / delta
}

ggplot(data = data.frame(x = 0:7), aes(x = x)) +
  stat_function(fun = dtukey, args = list(nmeans = 2, df = 10), 
                aes(colour = 'm = 2, df = 10'))+
    stat_function(fun = dtukey, args = list(nmeans = 2, df = 100), 
                  aes(colour = 'm = 2, df = 100'))+
  stat_function(fun = dtukey, args = list(nmeans = 3, df = 10), 
                aes(colour = 'm = 3, df = 10'))+
    stat_function(fun = dtukey, args = list(nmeans = 3, df = 100), 
                aes(colour = 'm = 3, df = 100'))+
  stat_function(fun = dtukey, args = list(nmeans = 5, df = 10), 
                aes(colour = 'm = 5, df = 10'))+
  stat_function(fun = dtukey, args = list(nmeans = 5, df = 100), 
                aes(colour = 'm = 5, df = 100')) +
  scale_colour_brewer('', palette = 'Paired') +
  labs(x = 'q', y = 'Плотность вероятности') +
  theme(legend.position = c(0.8, 0.6), legend.background = element_blank())
```


Формула для случая равных дисперсий и разных объемов групп:

$$q = \frac{\bar{y}_{max} - \bar{y}_{min}}{\sqrt{s^2\frac{1}{2} \large(\frac{1}{n_i} + \frac{1}{n_j}\large)}}$$


## Cтьюдентизированный t-критерий консервативнее обычного

\columnsbegin

\column{0.49\textwidth}

\centering\textbf{Обычный t-критерий}

\vspace{-1\baselineskip}

$$t = \frac{\bar{y}_i - \bar{y}_j}{\sqrt{MS_e \large(\frac{1}{n_i} + \frac{1}{n_j}\large)}}$$
\column{0.49\textwidth}

\centering\textbf{Стьюдентизированный t-критерий}

\vspace{-1\baselineskip}

$$q = \frac{\bar{y}_i - \bar{y}_j}{\sqrt{MS_e \;\frac{1}{2}  \; \large(\frac{1}{n_i} + \frac{1}{n_j}\large)}}$$

<!-- $$q = \frac{\bar{y}_i - \bar{y}_j}{\sqrt{MS_e \;\tikzmarkin<2>{factor} \frac{1}{2} \tikzmarkend{factor} \; \large(\frac{1}{n_i} + \frac{1}{n_j}\large)}}$$ -->
При этом $\bar{y}_i > \bar{y}_j$, т.е. вычитается из большего меньшее среднее.

\columnsend

\vspace{\baselineskip}
\pause

\centering{Значение $q$ будет в 1.414 раз больше, чем $t$.

\vspace{-1\baselineskip}

$$q = \frac{t}{\sqrt{\; \frac{1}{2}}} = \sqrt{2} \cdot t = 1.414 \cdot t$$}

<!-- $$q = \frac{t}{\sqrt{\; \tikzmarkin<2>{factor2} \frac{1}{2} \tikzmarkend{factor2} }} = \sqrt{2} \cdot t = 1.414 \cdot t$$} -->


## Тест Тьюки (Tuckey's Honest Significant Difference)

Используется стьюдентизированный t-критерий с $df = df_e = n - p$ и $m = p$ (общее число групп):

$$q = \frac{\bar{y}_i - \bar{y}_j}{\sqrt{MS_e\frac{1}{2} \large(\frac{1}{n_i} + \frac{1}{n_j}\large)}}$$

Требуется равенство дисперсий.

## Пост хок тесты различаются по степени консервативности


Если посмотреть на критические значения t при сравнении средних при $\alpha = 0.05$ ($m = 4$ группы по 6 наблюдений, $df_e = 20$), становится понятно, что тест Тьюки --- разумный компромисс среди пост хок тестов.


<!-- \begin{adjustbox}{max width=0.9\textwidth} -->
\begin{tabular}{p{4cm}|C{2cm}}
\textbf{Тест} & \textbf{Критическое значение}\\
\hline
Шеффе\textsuperscript{a} & 3.05\\
Бонферрони (4 группы) &  2.93 \\
\textbf{Тьюки (HSD)}\textsuperscript{b} &  2.80 \\
Бонферрони (3 группы) &  2.63 \\
Даннет\textsuperscript{b} &  2.54 \\
Дункан\textsuperscript{a, b} &  2.22 \\
Фишер (LSD) &  2.09 \\
\end{tabular}
<!-- \end{adjustbox} -->

\textsuperscript{a} \footnotesize{ --- Значение $t$ соответствующее $F$.} \newline 
\textsuperscript{b} \footnotesize{ --- Для сопоставимости внесена поправка $\sqrt{2}$.} 


## Пост хок тест Тьюки в R

- `glht()` --- "general linear hypotheses testing"
- `linfct` --- аргумент, задающий гипотезу для тестирования

- `mcp()` --- функция, чтобы задавать множественные сравнения (обычные пост хоки)
- `sp` = "Tukey" --- тест Тьюки по фактору `sp`

```{r, message=FALSE}
library(multcomp)
eggs_posthoc <- glht(mod_treatment, linfct = mcp(sp = "Tukey"))
```

## Результаты попарных сравнений (тест Тьюки) {.smaller}

Таблица результатов пост хок теста практически нечитабельна. 
\small

```{r}
summary(eggs_posthoc)
```

## Результаты пост хок теста

Результаты пост хок теста можно привести в виде текста...

- Размер яиц кукушек в гнездах крапивника значимо меньше, чем в гнездах лугового конька (тест Тьюки, $p < 0.01$). Размер яиц кукушек в гнездах лесной завирушки, белой трясогузки, малиновки и лесного конька не различается, но яйца кукушек в гнездах этих хозяев крупнее, чем в гнездах у лугового конька или крапивника (тест Тьюки, от $p < 0.01$ до $0.05$).

...или построить график

## Данные для графика при помощи `predict()`

```{r}
MyData <- data.frame(sp = factor(levels(eggs$sp), levels = levels(eggs$sp)))

MyData <- data.frame(
  MyData, 
  predict(mod_treatment, newdata = MyData, interval = "confidence"))

MyData
```

## Задание

Создайте MyData вручную:

- предсказанные значения 
- стандартные ошибки
- верхнюю и нижнюю границы доверительных интервалов

```{r eval=FALSE}
MyData <- data.frame(sp = factor(levels(eggs$sp), levels = levels(eggs$sp)))

X <- model.matrix()
betas <- 
MyData$fit <-  %*% 
MyData$se <- sqrt(diag(X %*% vcov(mod_treatment) %*% t(X)))
t_crit <- qt(p = , df = nrow() - length(coef()))
MyData$lwr <- MyData$ -  * MyData$
MyData$upr <- MyData$ +  * MyData$

```

## Решение:

```{r purl=FALSE}
MyData <- data.frame(sp = factor(levels(eggs$sp), levels = levels(eggs$sp)))
X <- model.matrix(~sp, data = MyData)
betas <- coef(mod_treatment)
MyData$fit <- X %*% betas
MyData$se <- sqrt(diag(X %*% vcov(mod_treatment) %*% t(X)))
t_crit <- qt(p = 0.975, df = nrow(eggs) - length(coef(mod_treatment)))
MyData$lwr <- MyData$fit - t_crit * MyData$se
MyData$upr <- MyData$fit + t_crit * MyData$se
MyData
```

## Столбчатый график

```{r}
gg_bars <- ggplot(data = MyData, aes(x = sp, y = fit)) + 
  geom_bar(stat = "identity", aes(fill = sp), width = 0.5) +
  geom_errorbar(aes(ymin = lwr, ymax = upr), width = 0.1) + 
  labs(x = "Вид хозяев", y = "Длина яиц кукушек, мм") +
  scale_fill_brewer(name = "Вид \nхозяев", palette = "Dark2") + 
  scale_x_discrete(labels = c("Крапивник", "Луговой\nконек", "Малиновка",
                            "Белая\nтрясогузка", "Лесной\nконек", "Лесная\nзавирушка")) + 
  theme(legend.position = "none")
gg_bars
```

## Можно привести результаты пост хок теста на столбчатом графике

Значимо различающиеся группы обозначим разными буквами

```{r}
gg_bars_coded <- gg_bars + 
  geom_text(aes(y = 1.6,  label = c("A", "B", "BC", "BC", "C", "C")), 
            colour = "white", size = 7)
gg_bars_coded
```


## Take home messages

- Дисперсионный анализ --- линейная модель с дискретными предикторами, существует в нескольких параметризациях, которые отличаются трактовками коэффициентов
- При помощи дисперсионного анализа можно проверить гипотезу о равенстве средних значений в группах
- Условия применимости дисперсионного анализа
    - Случайность и независимость групп и наблюдений внутри групп
    - Нормальное распределение в группах
    - Гомогенность дисперсий в группах
- При множественных попарных сравнениях увеличивается вероятность ошибки первого рода, поэтому нужно вносить поправку для уровня значимости
- Post hoc тесты --- это попарные сравнения после дисперсионного анализа, которые позволяют сказать, какие именно средние различаются

## Дополнительные ресурсы

- Quinn, Keough, 2002, pp. 173--207
- Logan, 2010, pp. 254--282
- [Open Intro to Statistics](http://www.openintro.org/stat/), pp.236--246 
- Sokal, Rohlf, 1995, pp. 179--260
- Zar, 2010, pp. 189-207
