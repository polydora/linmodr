---
title: "Обобщенные линейные модели с нормальным распределением остатков"
subtitle: "Линейные модели..."
author: "Марина Варфоломеева, Вадим Хайтов"
institute: "Кафедра Зоологии беспозвоночных, Биологический факультет, СПбГУ"
fontsize: 10pt
classoption: 't,xcolor=table'
language: russian, english
output:
  beamer_presentation:
    theme: default
    toc: no
    colortheme: beaver
    latex_engine: xelatex
    slide_level: 2
    fig_crop: false
    highlight: tango
    includes:
      in_header: ./includes/header.tex
---

```{r setup, include = FALSE, cache = FALSE, purl = FALSE}
options(width = 70, scipen = 4)
library(knitr)
# chunk default options
opts_chunk$set(fig.show='hold', size='footnotesize', comment="#", warning=FALSE, message=FALSE, dev='cairo_pdf', fig.height=2.5, fig.width=7.7, R.options=list(width=70))
# library("extrafont")
source("support_linmodr.R")
```

## Мы рассмотрим 

+ Варианты анализа для случаев, когда зависимая перменная --- счетная величина (целые неотрицательные числа)

###  Вы сможете

+ Объяснить особенности разных типов распределений, принадлежащих экспоненциальному семейству. 
+ Построить пуасоновскую и квази-пуассоновскую линейную модель
+ Объяснить проблемы, связанные с избыточностью дисперсии в модели
+ Построить модель, основанную на отрицательном биномиальном распределении


## Распределение Пуассона 

\columnsbegin
\column{0.48\textwidth}

```{r echo=FALSE, purl=FALSE, fig.width=2.32*1.5, out.width='2.32in', fig.height=3.38, out.height='2.25in'}
library(ggplot2)
mu1 <- 1
mu2 <- 5
mu3 <- 10
mu4 <- 20
y <- seq(0, 35, by = 1)

pi <- data.frame(
  y = rep(y, 4),  
  pi = c(dpois(y, mu1), dpois(y, mu2), dpois(y, mu3), dpois(y, mu4)), 
  mu = rep(c(mu1, mu2, mu3, mu4), each = length(y))
)

ggplot(pi, aes(x = y, y = pi)) + 
  geom_bar(stat = "identity", fill = 'grey20') + 
  facet_wrap(~ mu, nrow = 2, labeller = label_both) + 
  # ggtitle("Распределение Пуассона \nпри разных параметрах") + 
  ylab("f(y)")
```

\column{0.42\textwidth}

\vspace{-\baselineskip}

$$f(y)= \frac{\mu^y \cdot e^{-\mu}}{y!}$$

Параметр:

- $\mu$ -- задает среднее и дисперсию


\vspace{\baselineskip}

Свойства:

- $E(y) = \mu$ --- мат.ожидание
- $var(y) = \mu$ --- дисперсия
- $0 \le y \le +\infty$, $y \in \mathbb{N}$ --- значения


\columnsend

## Отрицательное биномиальное распределение

\columnsbegin
\column{0.48\textwidth}

```{r echo=FALSE, purl=FALSE, fig.width=3.75, out.width='2.5in', fig.height=3.38, out.height='2.25in'}
mu1 <- 1
mu2 <- 5
k1 <- 0.1
k2 <- 100
y <- 0:30

pi <- data.frame(
  y = rep(y, 4), 
  pi = c(dnbinom(y, size = k1, mu = mu1), 
         dnbinom(y, size = k1, mu = mu2), 
         dnbinom(y, size = k2, mu = mu1), 
         dnbinom(y, size = k2, mu = mu2)), 
  mu = rep(c(mu1, mu2), each = 2*length(y)), 
  k = rep(c(k1, k2, k1, k2), each = length(y)) )

ggplot(pi, aes(x = y, y = pi)) + 
  geom_bar(stat = "identity", fill = 'grey20') + 
  facet_grid(mu~k, labeller = label_both, scales = "free_y") + 
  # ggtitle("Отрицательное биномиальное распределение \nпри разных параметрах") + 
  ylab("f(y)")
```

\column{0.42\textwidth}

\vspace{-\baselineskip}

$$f(y) = \frac{\Gamma(y + k)}{\Gamma(k) \cdot \Gamma(y+1)} \cdot (\frac{k}{\mu + k})^k \cdot (1 - \frac{k}{\mu + k})^y$$

Параметры: 

- $\mu$ -- среднее  
- $k$ -- определяет степень избыточности дисперсии

\vspace{\baselineskip}

Свойства:

- $E(y)  = \mu$ -- мат.ожидание
- $var(y) = \mu + \frac {\mu^2}{k}$ -- дисперсия
- $0 \le y \le +\infty$, $y \in \mathbb{N}$ -- значения

\note{Это смесь Пуассоновского и Гамма распределений: $y$ подчиняется распределению Пуассона с Гамма-распределенным $\mu$. Приближается к распр. Пуассона при очень больших $k$.}

\columnsend


## GLM в "туннеле" из распределений

В каждом конкретном случае при анализе данных нам предстоит выяснить, какое из распределений больше подходит для моделирования отклика.

- Достаточно ли возможностей распределения Пуассона, чтобы описать связь среднего и дисперсии? 
- Если нет, то справится ли отрицательное биномиальное распределениие, у которого есть параметр, для описания этой связи?


```{r echo=FALSE, fig.height=2.5*1.5, out.height='2.5in'}
# A Graphical Look at Poisson Regression
# https://bookdown.org/roback/bookdown-bysh/ch-poissonreg.html
# https://github.com/broadenyourstatisticalhorizons/bysh_book/blob/1be2441d7dc0ac57e428218cac504ed3147fd8c6/04-Poisson-Regression.Rmd#L109

library(dplyr)
library(tidyr)
library(ggplot2)    # enable ggplot
library(gridExtra)  # enable multiple plotting
library(MASS)

# Now make Poisson regression picture
set.seed(42)
nbreaks <- 6
b0 <- 0
b1 <- 0.1
N <- 1000


dat <- data.frame(x=(x = runif(N, 0, 20)),
                  y=rpois(N, lambda = exp(b0  + b1 * x)))
## breaks: where you want to compute densities
breaks <- seq(0, max(dat$x), len=nbreaks)
dat$section <- cut(dat$x, breaks)

## Get the residuals
dat$res <- dat$y - (b0  + b1 * dat$x)
## Compute densities for each section, flip the axes, add means of sections
## Note: densities need to be scaled in relation to section size
dens <- do.call(rbind, lapply(split(dat, dat$section), function(x) {
  d <- density(x$res, n=500)
  res <- data.frame(x = max(x$x) - d$y * 10, y = d$x + mean(x$y))
  res <- res[order(res$y), ]
  n_obs <- nrow(res)
  ## Get some data for poisson lines as well
  xs <- seq(min(x$y), max(x$y), len = 500)
  res <- rbind(res, data.frame(y = xs,
                               x = max(x$x) - 10 * dpois(round(xs), exp(b0 + b1 * max(x$x) ))))
  res$type <- rep(c("empirical", "poisson"), each = n_obs)
  res
}))

dens$section <- rep(levels(dat$section), each=N)

pois_assume <- ggplot(dat, aes(x, y)) +
  geom_point(size = 0.75, alpha = 0.5, position = position_jitter(height = 0.1)) +
  geom_smooth(method="loess", fill=NA, lwd=1) +
  geom_path(data=dens[dens$type=="poisson",], aes(x, y, group=section),
            color='red', lwd=1.1) +
  # geom_path(data=dens[dens$type=="empirical",], aes(x, y, group=section),
  #           color="powderblue", lwd=1.1) +
  theme_bw() +
  geom_vline(xintercept=breaks, lty=1, colour = 'grey80')
# pois_assume


# Negative Binomial
set.seed(42)
th <- 10
dat <- data.frame(x=runif(N, 0, 20),
                  y=rnegbin(N, mu = exp(b0  + b1 * x), theta = th))
## breaks: where you want to compute densities
breaks <- seq(0, max(dat$x), len=nbreaks)
dat$section <- cut(dat$x, breaks)
## Get the residuals
dat$res <- dat$y - (b0  + b1 * dat$x)
## Compute densities for each section, flip the axes, add means of sections
## Note: densities need to be scaled in relation to section size
dens <- do.call(rbind, lapply(split(dat, dat$section), function(x) {
  d <- density(x$res, n=500)
  res <- data.frame(x = max(x$x) - d$y * 10, y = d$x + mean(x$y))
  res <- res[order(res$y), ]
  n_obs <- nrow(res)
  ## Get some data for nb lines as well
  xs <- seq(min(x$y), max(x$y), len = 500)
  res <- rbind(res, data.frame(y = xs,
                               x = max(x$x) - 10 * dnbinom(round(xs), mu = exp(b0 + b1 * max(x$x) ), size = th)))
  res$type <- rep(c("empirical", "nb"), each = n_obs)
  res
}))

dens$section <- rep(levels(dat$section), each=N)

nb_assume <- ggplot(dat, aes(x, y)) +
  geom_point(size = 0.75, alpha = 0.5, position = position_jitter(height = 0.1)) +
  geom_smooth(method="loess", fill=NA, lwd=1) +
  geom_path(data=dens[dens$type=="nb",], aes(x, y, group=section),
            color='red', lwd=1.1) +
  # geom_path(data=dens[dens$type=="empirical",], aes(x, y, group=section),
            # color="powderblue", lwd=1.1) +
  theme_bw() +
  geom_vline(xintercept=breaks, lty=1, colour = 'grey80')
# nb_assume

grid.arrange(
  pois_assume + 
    labs(title = 'GLM с Пуассоновским \nраспределением отклика') +
    coord_cartesian(ylim = c(0, 20)),
  nb_assume + 
    labs(title = 'GLM с отрицательным биномиальным \nраспределением отклика') +
    coord_cartesian(ylim = c(0, 20)),
  ncol = 2)
```


## Гадючий лук, копеечник и визиты опылителей

Гадючий лук (мускари, _Leopoldia comosa_) --- представитель родной флоры острова Менорка. В 18-19вв на остров завезли копеечник венечный (_Hedysarum coronarium_), который быстро натурализовался. Оба вида цветут одновременно и нуждаются в опылении насекомыми.

Как зависит число визитов опылителей на цветки мускари от присутствия вселенца и разнообразия флоры в ближайшей окрестности? (Данные Montero-Castaño, Vilà, 2015)

\columnsbegin
\column{0.48\textwidth}

\includegraphics[height=1.7in,keepaspectratio]{images/Muscari_comosum.JPG}

\footnotesize

Muscari à toupet (Muscari comosum), Dordogne, France --- Père Igor

\column{0.48\textwidth}

\includegraphics[clip, trim=0in 0in 0.65in 0in, height=1.7in,keepaspectratio]{images/Hedysarum-coronarium.jpg}

\footnotesize

French-honeysuckle. Close to Santadi Basso, Sardinia, Italy --- Hans Hillewaert

\note{\url{https://doi.org/10.1371/journal.pone.0128595}}

\columnsend

## Дизайн исследования

Подсчитывали число визитов опылителей на выбранное растение гадючьего лука \newline (в пунктирной рамке) на трех типах участков.

\includegraphics[width=0.7\textwidth, height=0.7\textwidth, natwidth=997, natheight=636, keepaspectratio]{images/journal.pone.0128595.g002.PNG}

\footnotesize

Fig.2 из Montero-Castaño, Vilà, 2015

\url{https://doi.org/10.1371/journal.pone.0128595}


## Переменные

- `Visits` --- число визитов всех опылителей на цветок _Leopoldia_

- `Treatment` --- тип площадки, тритмент (фактор с 3 уровнями):
    - `Invaded` --- _Leopoldia_ в смеси с видом-вселенцем;
    - `Removal` --- _Leopoldia_ в смеси с видом-вселенцем с удаленными цветками; 
    - `Control` --- _Leopoldia_ без вида вселенца.

- `DiversityD_1` --- Разнообразие флоры на площадке ($exp(H’)$,  где $H'$ --- индекс Шеннона-Уивера) \newline (на луг с более разнообразной растительностью прилетит больше опылителей).

- `Flowers` --- число цветков _Leopoldia_ на площадке (чем больше, тем больше опылителей).

- `Hours` --- продолжительность наблюдений (чем дольше, тем больше насчитали).


Другие переменные:

- `Total_1` --- общая плотность цветков
- `Visits_NO_Apis` --- посещения опылителей без учета пчел
- `Fruit` --- число цветов с плодами через месяц
- `No_Fruit` --- число цветов без плодов через месяц


## Открываем из знакомимся с данными

\small

```{r data, }
library(readxl)
pol <- read_excel("data/Pollinators_Montero-Castano, Vila, 2015.xlsx", sheet = 1)
head(pol)
```

Сколько пропущенных значений?

```{r}
colSums(is.na(pol))
```


## Есть ли выбросы?

```{r}
library(cowplot)
library(ggplot2)
theme_set(theme_bw())

dot_plot <- ggplot(pol, aes(y = 1:nrow(pol))) + geom_point()
plot_grid(dot_plot + aes(x = DiversityD_1), dot_plot + aes(x = Flowers),
          dot_plot + aes(x = Hours), nrow = 1)
```

Выбросов нет.

Периоды наблюдений имеют разную продолжительность. Нужно это учесть в модели.

## Каков объем выборки?

```{r}
table(pol$Treatment)
```

Как распределены короткие периоды наблюдений по тритментам?

```{r}
table(pol$Hours, pol$Treatment)
```

## Коллинеарны ли непрерывные и дискретные предикторы?

```{r}
box_plot <- ggplot(pol, aes(x = Treatment)) + geom_boxplot()

plot_grid(box_plot + aes(y = DiversityD_1),
          box_plot + aes(y = Flowers), nrow = 1)
```

Возможно, есть коллинеарность.


## Как распределена переменная-отклик?


```{r fig.show='asis'}
ggplot(pol, aes(x = Visits)) + geom_histogram()
mean(pol$Visits == 0) # Какова пропорция нулей?
```

Число визитов насекомых -- счетная переменная. Для ее моделирования нужно использовать подходящее распределение.

Примерно `r round(mean(pol$Visits == 0) * 100)` \% наблюдений -- нули. Иногда из-за избытка нулей (Zero inflation) в модели может появиться избыточность дисперсии. Будем иметь это в виду.


## Линейна ли связь между предикторами и откликом?

```{r}
gg_shape <- ggplot(pol, aes(y = Visits/Hours, colour = Treatment)) +
  theme(legend.position = 'bottom')
plot_grid(
  gg_shape + geom_point(aes(x = Flowers)),
  gg_shape + geom_point(aes(x = DiversityD_1)),
nrow = 1)
```

Связь практически линейна.

## Если мы (ошибочно) подберем \newline GLM с нормальным распределением отклика?

$Visits_i \sim N(\mu_i, \sigma)$ 

$E(Visits_i) = \mu_i$, $var(Visits_i) = \sigma^2$

$\mu_i = \eta_i$ -- функция связи "идентичность"

$\eta_i = b_0 + b_1 Treatment_{Invaded\ i} + b_2 Treatment_{Removal\ i} + b_3 DiversityD1_{i} + b_4 Flowers_{i} + b_5 Hours_{i}$


\vspace{\baselineskip}

```{r }
M_norm <- glm(Visits ~ Treatment + DiversityD_1 + Flowers + Hours, data = pol)
coef(M_norm)
sigma(M_norm)
```

## Данные для графика предсказаний простой линейной модели


```{r}
library(dplyr)
NewData <- pol %>% group_by(Treatment)%>%
  do(data.frame(Flowers = seq(min(.$Flowers), max(.$Flowers), length.out=50))) %>%
  mutate(DiversityD_1 = mean(pol$DiversityD_1),
         Hours = 0.75)

# Модельная матрица и коэффициенты
X <- model.matrix(~ Treatment + DiversityD_1 + Flowers + Hours, data = NewData)
betas <- coef(M_norm)
# Предсказания в масштабе функции связи (eta) совпадают с масштабом отклика (mu)
NewData$mu <- X %*% betas       
NewData$SE_mu <- sqrt(diag(X %*% vcov(M_norm) %*% t(X)))  # SE

head(NewData, 3)
```

## График предсказаний

```{r}
ggplot(NewData, aes(x = Flowers, y = mu, fill = Treatment)) +
  geom_ribbon(aes(ymin = mu - 2 * SE_mu, ymax = mu + 2 * SE_mu), alpha=0.3)+
  geom_line(aes(colour = Treatment)) +
  geom_hline(yintercept = 0)
```


## Смотрим на результаты подбора модели

\footnotesize

```{r}
summary(M_norm)
```

## Анализ девиансы для модели с нормальным распределением отклика


```{r}
drop1(M_norm, test = 'Chi')
```

\vspace{\baselineskip}

Число визитов опылителей на цветки гадючьего лука:

- НЕ зависит от присутствия вселенца и его цветов,
- НЕ зависит от разнообразия флоры на участке,
- зависит от числа цветов самого гадючьего лука.
    
\vspace{\baselineskip}

Можем ли мы доверять этим результатам? Пока не известно.


## Нет ли коллинеарности предикторов


```{r}
library(car)
vif(M_norm)
```

Коллинеарности нет.

## Задание 1

Постройте график пирсоновских остатков от предсказанных значений для модели `M_norm`.

Какие нарушения условий применимости вы на нем видите?

\vspace{\baselineskip}

Дополните код:

```{r eval=FALSE}
M_norm_diag <- data.frame(.fitted = fitted(),
                          .resid_p = residuals())

ggplot(data = , aes()) + geom_hline( = 0) + 
  geom_point()
```


## График остатков от предсказанных значений


```{r fig.height=2.4, purl=FALSE}
M_norm_diag <- data.frame(.fitted = fitted(M_norm, type = "response"),
                          .resid_p = residuals(M_norm, type = "pearson"))

ggplot(M_norm_diag, aes(y = .resid_p)) + geom_hline(yintercept = 0) + 
  geom_point(aes(x = .fitted))
```


Гетерогенность дисперсий остатков.

Отрицательные предсказания!


## Модель с нормальным распределением отклика не подходит

Два способа решения проблем с моделью:

1. Грубый способ: логарифмировать зависимую переменную и построить модель для нее. 
2. Лучше построить модель, основанную на распределении, подходящем для счетных данных:
    - распределение Пуассона,
    - отрицательное биномиальное распределение.


## GLM с Пуассоновским распределением отклика

$Visits_i \sim Poisson(\mu_i)$

$E(Visits_i) = \mu_i$, $var(Visits_i) = \mu_i$

$\text{ln}(\mu_i) = \eta_i$ --- функция связи логарифм

$\begin{aligned}\eta_i & =  b_0 + b_1 Treatment_{Invaded\ i} + b_2 Treatment_{Removal\ i} + \\ &+ b_3 DiversityD1_{i} + b_4 Flowers_{i} + b_5 Hours_{i}\end{aligned}$

\vspace{\baselineskip}

```{r }
M_pois <- glm(Visits ~ Treatment + DiversityD_1 + Flowers + Hours, data = pol,
                   family = "poisson")

```

## Уравнение модели с Пуассоновским распределением отклика

$Visits_i \sim Poisson(\mu_i)$

$E(Visits_i) = \mu_i$, $var(Visits_i) = \mu_i$

$\text{ln}(\mu_i) = \eta_i$

$\begin{aligned}\eta_i = &-2.66 + 0.71 Treatment_{Invaded\ i} - 0.22 Treatment_{Removal\ i} - \\ &- 0.46 DiversityD1_i + 0.04  Flowers_i + 4.69 Hours_i\end{aligned}$

\vspace{\baselineskip}

```{r R.options=list(width=60)}
coef(M_pois)
```

## Смотрим на результаты подбора модели

\vspace{-\baselineskip}

\columnsbegin
\column{0.7\textwidth}

\footnotesize

```{r}
summary(M_pois)
```

\column{0.3\textwidth}

Угловые коэффициенты показывают, на сколько единиц меняется значение логарифма отклика, если соответствующий предиктор изменяется на единицу.

Это значит, что сам отклик изменяется в $e^{b_k}$ раз при изменении предиктора на единицу.

\columnsend


## Анализ девиансы для модели с Пуассоновским распределением отклика


```{r}
drop1(M_pois, test = 'Chi')
```

\vspace{\baselineskip}

Число визитов опылителей на цветки гадючьего лука:

- зависит от присутствия вида вселенца и его цветов,
- зависит от разнообразия флоры на данном участке,
- зависит от числа цветов самого гадючьего лука.
    
\vspace{\baselineskip}

Можем ли мы доверять этим результатам? Пока не известно.


## Данные для предсказаний

```{r}
NewData <- pol %>% group_by(Treatment)%>%
  do(data.frame(Flowers = seq(min(.$Flowers), max(.$Flowers), length.out=50))) %>% 
  mutate(DiversityD_1 = mean(pol$DiversityD_1),
         Hours = 0.75)
```

Давайте получим предсказания при помощи операций с матрицами,  
чтобы своими глазами увидеть работу функции связи.

Еще можно получить предсказания при помощи функции `predict()`. Но будьте осторожны, **predict() возвращает стандартные ошибки все время только в масштабе функции связи!**

```{r eval=FALSE}
?predict.glm
```


## Предсказания модели при помощи операций с матрицами


```{r}
# Модельная матрица и коэффициенты
X <- model.matrix(~ Treatment + DiversityD_1 + Flowers + Hours, data = NewData)
betas <- coef(M_pois)

# Предсказанные значения и стандартные ошибки...
# ...в масштабе функции связи (логарифм)
NewData$fit_eta <- X %*% betas       
NewData$SE_eta <- sqrt(diag(X %*% vcov(M_pois) %*% t(X)))

# ...в масштабе отклика (применяем функцию, обратную функции связи)
NewData$fit_mu <- exp(NewData$fit_eta)
NewData$lwr <- exp(NewData$fit_eta - 2 * NewData$SE_eta)
NewData$upr <- exp(NewData$fit_eta + 2 * NewData$SE_eta)

head(NewData, 2)
```

## График предсказаний в масштабе функции связи


```{r}
ggplot(NewData, aes(x = Flowers, y = fit_eta, fill = Treatment)) +
  geom_ribbon(aes(ymin = fit_eta - 2 * SE_eta, 
                  ymax = fit_eta + 2 * SE_eta), 
              alpha = 0.5) +
  geom_line(aes(colour = Treatment)) + 
  geom_hline(yintercept = 0)
```


В масштабе функции связи мы моделируем линейную зависимость логарифмов мат. ожидания отклика от предикторов.


## График предсказаний в масштабе переменной-отклика


```{r}
ggplot(NewData, aes(x = Flowers, y = fit_mu, fill = Treatment)) +
  geom_ribbon(aes(ymin = lwr, 
                  ymax = upr), 
              alpha = 0.5) +
  geom_line(aes(colour = Treatment)) + 
  geom_hline(yintercept = 0)
```


GLM с Пуассоновским распределением отклика моделирует его нелинейную cвязь предикторами за счет функции связи $log()$.



## Возможные проблемы GLM с Пуассоновским распределением отклика

GLM с Пуассоновским распределением отклика учитывает гетерогенность дисперсии ($var(y_i) = mu_i = E(y_i)$). Стандартные ошибки возрастают с увеличением предсказанного значения.

Но достаточно ли этого для моделирования данных? Нет ли здесь сверхдисперсии?

```{r echo=FALSE}
ggplot(NewData, aes(x = Flowers, y = fit_mu, fill = Treatment)) +
  geom_ribbon(aes(ymin = lwr, 
                  ymax = upr), 
              alpha = 0.5) +
  geom_line(aes(colour = Treatment)) + 
  geom_hline(yintercept = 0)
```


## Условия применимости GLM с Пуассоновским распределением отклика

- Случайность и независимость наблюдений внутри групп.
- Отсутствие сверхдисперсии. (Дисперсия остатков равна мат.ожиданию при каждом уровне значений предикторов).
- Отсутствие коллинеарности предикторов.

## График остатков

```{r}
M_pois_diag <- data.frame(.fitted = fitted(M_pois, type = "response"),
                            .resid_p = residuals(M_pois, type = "pearson"))
ggplot(M_pois_diag, aes(x = .fitted, y = .resid_p)) + 
  geom_point() + 
  geom_hline(yintercept = 0)
```


## Избыточность дисперсии (overdispersion)

Если данные подчиняются распределению Пуассона, то дисперсия должна быть равна среднему значению.

- $E(y_i)  = \mu_i$
- $var(y_i) = \mu_i$

Если это не так, то мы не сможем доверять результатам. Это будет значить, что мы применяем модель, основанную на Пуассоновском распределении, к данным, которые не подчиняются этому распределению. 


## Проверка на сверхдисперсию

Используем предложенную Беном Болкером функцию проверки на сверхдисперсию

```{r}
# Функция для проверки наличия сверхдисперсии в модели (автор Ben Bolker)
# http://bbolker.github.io/mixedmodels-misc/glmmFAQ.html
# Код модифицирован, чтобы учесть дополнительный параметр в NegBin GLMM, подобранных MASS::glm.nb()
overdisp_fun <- function(model) {
    rdf <- df.residual(model)  # Число степеней свободы N - p
    if (any(class(model) == 'negbin')) rdf <- rdf - 1 ## учитываем k в NegBin GLMM
    rp <- residuals(model,type='pearson') # Пирсоновские остатки
    Pearson.chisq <- sum(rp^2) # Сумма квадратов остатков, подчиняется Хи-квадрат распределению 
    prat <- Pearson.chisq/rdf  # Отношение суммы квадратов остатков к числу степеней свободы
    pval <- pchisq(Pearson.chisq, df=rdf, lower.tail=FALSE) # Уровень значимости
    c(chisq=Pearson.chisq,ratio=prat,rdf=rdf,p=pval)        # Вывод результатов
}
```

Ben Bolker's glmmFAQ  
\url{http://bbolker.github.io/mixedmodels-misc/glmmFAQ.html}

\vspace{\baselineskip}

```{r}
overdisp_fun(M_pois)
```

Избыточность дисперсии есть! Дисперсия в `r as.numeric(round(overdisp_fun(M_pois)[2], 1))` раза выше среднего.

## Если есть избыточность дисперсии...

Пуассоновские модели недооценивают (приуменьшают) "раздувшиеся" стандартные ошибки.

Если данные подчиняются распределению Пуассона, то:

$var(y_i) = \mu_i$

\vspace{\baselineskip}

$var(E(y_i)) = {\mu_i} / n$

$SE_{E(y_i)} = \sqrt {var(E(y_i))}$

\vspace{\baselineskip}

Если данные не подчиняются распределению Пуассона, и дисперсия в $\varphi$ раз больше среднего ($\varphi > 1$), то:

$var^*(y_i) = \varphi\mu_i$

Тогда дисперсии и стандартные ошибки "раздуты":

$var(E(y_i)) = {\varphi\mu_i} / n$

$SE_{E(y_i)} = \sqrt {\varphi~var(E(y_i))}$


## Проблемы из-за неучтенной избыточности дисперсии

Когда есть избыточность дисперсии, использование распределения Пуассона приведет к проблемам:

- Доверительная зона предсказаний модели будет заужена из-за того, что оценки стандартных ошибок занижены.

- Тесты Вальда для коэффициентов модели дадут неправильные результаты из-за того, что оценки стандартных ошибок занижены. Уровень значимости будет занижен.

- Тесты, основанные на сравнении правдоподобий дадут смещённые результаты,   
т.к. соотношение девианс уже не будет подчиняться $\chi^2$-распределению.

## Причины избыточности дисперсии 

+ Наличие выбросов.
+ В модель не включен важный предиктор или взаимодействие предикторов.
+ Нарушена независимость выборок (есть внутригрупповые корреляции).
+ Нелинейная связь между ковариатами и зависимой переменной.
+ Выбрана неподходящая связывающая функция.
+ Количество нулей больше, чем предсказывает выбранное \newline распределение отклика (Zero inflation) .
+ Выбрана неподходящая функция распределения для отклика.

\pause

### Как бороться с избыточностью дисперсии

Взвесив все, что известно о данных, можно решить, как именно усовершенствовать модель.

\vspace{\baselineskip}

Для модели числа визитов опылителей мы попробуем два варианта действий:

- Можно построить квази-пуассоновскую модель.
- Можно построить модель, основанную на отрицательном биномиальном распределении.

## Квази-пуассоновские модели

\columnsbegin
\column{0.7\textwidth}

$Visits_i \sim Quasipoisson(\mu_i)$

$E(Visits_i) = \mu_i$, $var(y_i) = \varphi\ \mu_i$

$\text{ln}(\mu_i) = \eta_i$ --- функция связи логарифм

$\begin{aligned}\eta_i & =  b_0 + b_1 Treatment_{Invaded\ i} + b_2 Treatment_{Removal\ i} + \\ &+ b_3 DiversityD1_{i} + b_4 Flowers_{i} + b_5 Hours_{i}\end{aligned}$

\column{0.3\textwidth}

Помните, не бывает  
"квази-пуассоновского  
распределения"!  

\columnsend

В этих моделях используется распределение Пуассона, но вводится поправка на степень избыточности дисперсии $\varphi$.

Величина $\varphi$ показывает, во сколько раз дисперсия превышает среднее. 

$\varphi$ оценивается по данным.

<!-- Вот такой вариант оценки используется в R (рекомендован McCullagh, Nelder, 1989): -->

<!-- $$\varphi =  \frac{var(E(y_i))}{\mu_i}=\frac {\frac{\sum{(e_{p~i})^2}}{n - p}}  {\mu_i} =  \frac{\sum{(e_{p~i})^2}}{n - p}$$ -->

## Особенности квази-пуассоновской GLM

- Оценки параметров $\beta$ такие же как в Пуассоновской GLM.
- Стандартные ошибки оценок коэффициентов домножены на $\sqrt{\varphi}$.
- Доверительные интервалы к оценкам коэффициентов домножены на $\sqrt{\varphi}$.
- Логарифмы правдоподобий уменьшаются в $\varphi$ раз.

\note{(см. Højsgaard and Halekoh 2005)}

\pause

### Особенности работы с квази-моделями

1. В тестах параметров используются $t$-тесты (и $t$-распределение) вместо $z$-тестов Вальда (и стандартного нормального распределения).

2. Для анализа девиансы используются $F$-тесты.

3. Для квази-пуассоновских моделей не определена функция максимального правдоподобия, поэтому нельзя вычислить AIC (но иногда считают квази-AIC = QAIC).


## Подбираем квази-пуассоновскую модель {.smaller}

$Visits_i \sim Quasipoisson(\mu_i)$

$E(Visits_i) = \mu_i$, $var(Visits_i) = \varphi\ \mu_i$

$\text{ln}(\mu_i) = \eta_i$ --- функция связи логарифм

$\begin{aligned}\eta_i & =  b_0 + b_1 Treatment_{Invaded\ i} + b_2 Treatment_{Removal\ i} + \\ &+ b_3 DiversityD1_{i} + b_4 Flowers_{i} + b_5 Hours_{i}\end{aligned}$

\vspace{\baselineskip}

```{r}
M_quasi <- glm(Visits ~ Treatment + DiversityD_1 + Flowers + Hours, data = pol, 
                 family = "quasipoisson")
```

## Уравнение квази-пуассоновской модели

$Visits_i \sim Quasipoisson(\mu_i)$

$E(Visits_i) = \mu_i$, $var(Visits_i) = 3.016\ \mu_i$

$\text{ln}(\mu_i) = \eta_i$

$\begin{aligned}\eta_i = &-2.66 + 0.71 Treatment_{Invaded\ i} - 0.22 Treatment_{Removal\ i} - \\ &- 0.46 DiversityD1_i + 0.04  Flowers_i + 4.69 Hours_i\end{aligned}$

\vspace{\baselineskip}

```{r }
coef(M_quasi)
summary(M_quasi)$dispersion
```

## Смотрим на результаты подбора модели

\footnotesize

```{r}
summary(M_quasi)
```

## Анализ девиансы для квази-пуассоновской модели


```{r}
drop1(M_quasi, test = "F")
```

\vspace{\baselineskip}

Число визитов опылителей на цветки гадючьего лука:

- зависит от присутствия вида вселенца и его цветов,
- зависит от разнообразия флоры на данном участке,
- зависит от числа цветов самого гадючьего лука.

\vspace{\baselineskip}

Можем ли мы доверять этим результатам?  Это приблизительные результаты.  Не\ стоит доверять $p$ близким к $\alpha = 0.05$.


## GLM с отрицательным биномиальным распределением отклика

$Visits_i \sim NB(\mu_i, k)$

$E(Visits_i) = \mu_i$, $var(Visits_i) = \mu_i + \frac{\mu_i^2}{k}$

$\text{ln}(\mu_i) = \eta_i$ -- функция связи логарифм

$\eta = b_0 + b_1 Treatment_{Invaded\ i} + b_2 Treatment_{Removal\ i} +$  
$+ b_3 DiversityD1_{i} + b_4 Flowers_{i} + b_5 Hours_{i}$

\vspace{\baselineskip}

```{r}
library(MASS)
M_nb <- glm.nb(Visits ~ Treatment + DiversityD_1 + Flowers + Hours, data = pol, 
                 link = "log")
```

## Уравнение модели с отрицательным биномиальным распределением отклика

$Visits_i \sim NB(\mu_i, 1.936)$

$E(Visits_i) = \mu_i$, $var(Visits_i) = \mu_i + \frac{\mu_i^2}{1.936}$

$\text{ln}(\mu_i) = \eta_i$

$\eta_i = -1.97 + 0.57 Treatment_{Invaded\ i} - 0.11 Treatment_{Removal\ i} -$  
$- 0.49 DiversityD1_{i} + 0.03 Flowers_{i} + 4.10 Hours_{i}$

\vspace{\baselineskip}

```{r }
coef(M_nb)
summary(M_nb)$theta
```

## Смотрим на результаты подбора модели

\vspace{-0.7\baselineskip}

\columnsbegin
\column{0.7\textwidth}

\footnotesize

```{r}
summary(M_nb)
```

\column{0.3\textwidth}

Угловые коэффициенты показывают, на сколько единиц меняется значение логарифма отклика, если соответствующий предиктор изменяется на единицу.

Это значит, что сам отклик изменяется в $e^{b_k}$ раз при изменении предиктора на единицу.

\columnsend


## Анализ девиансы модели с отрицательным биномиальным распределением отклика


```{r}
drop1(M_nb, test = 'Chi')
```

\vspace{\baselineskip}

Число визитов опылителей на цветки гадючьего лука:

- не зависит от присутствия вида вселенца и его цветов,
- зависит от разнообразия флоры на данном участке,
- зависит от числа цветов самого гадючьего лука.

\vspace{\baselineskip}

Можем ли мы доверять этим результатам? Это нужно еще проверить.

## Задание 2

Проведите диагностику модели `M_nb`.

Видите ли вы какие-нибудь нарушения условий применимости?

## График остатков

```{r}
M_nb_diag <- data.frame(.fitted = fitted(M_nb, type = "response"),
                          .resid_p = residuals(M_nb, type = "pearson"),
                          pol)
gg_resid <- ggplot(M_nb_diag, aes(y = .resid_p)) + geom_hline(yintercept = 0)
gg_resid + geom_point(aes(x = .fitted))
```

## Проверка на сверхдисперсию

Обратите внимание, у моделей с отрицательным биномиальным распределением добавляется еще один параметр

```{r}
overdisp_fun(M_nb)
```

Избыточности дисперсии нет

## Графики остатков от переменных, которые есть в модели

```{r}
plot_grid(gg_resid + geom_boxplot(aes(x = Treatment)),
          gg_resid + geom_boxplot(aes(x = as.factor(Hours))),
          gg_resid + geom_point(aes(x = DiversityD_1)),
          gg_resid + geom_point(aes(x = Flowers)),
          nrow = 2)
```

## Графики остатков от переменных, которых нет в модели

```{r}
gg_resid + geom_point(aes(x = Total_1))
```


## Данные для предсказаний

```{r}
NewData <- pol %>% group_by(Treatment)%>%
  do(data.frame(Flowers = seq(min(.$Flowers), max(.$Flowers), length.out=50))) %>% 
  mutate(DiversityD_1 = mean(pol$DiversityD_1),
         Hours = 0.75)
```

Как и в прошлый раз, давайте получим предсказания при помощи операций с матрицами,  
чтобы своими глазами увидеть работу функции связи.

Еще можно получить предсказания при помощи функции `predict()`. Но будьте осторожны, **predict() возвращает стандартные ошибки все время только в масштабе функции связи!**


## Предсказания модели при помощи операций с матрицами


```{r}
# Модельная матрица и коэффициенты
X <- model.matrix(~ Treatment + DiversityD_1 + Flowers + Hours, data = NewData)
betas <- coef(M_nb)

# Предсказанные значения и стандартные ошибки...
# ...в масштабе функции связи (логарифм)
NewData$fit_eta <- X %*% betas       
NewData$SE_eta <- sqrt(diag(X %*% vcov(M_nb) %*% t(X)))

# ...в масштабе отклика (применяем функцию, обратную функции связи)
NewData$fit_mu <- exp(NewData$fit_eta)
NewData$lwr <- exp(NewData$fit_eta - 2 * NewData$SE_eta)
NewData$upr <- exp(NewData$fit_eta + 2 * NewData$SE_eta)

head(NewData, 2)
```

## График предсказаний в масштабе функции связи


```{r}
ggplot(NewData, aes(x = Flowers, y = fit_eta, fill = Treatment)) +
  geom_ribbon(aes(ymin = fit_eta - 2 * SE_eta, 
                  ymax = fit_eta + 2 * SE_eta), 
              alpha = 0.5) +
  geom_line(aes(colour = Treatment)) + 
  geom_hline(yintercept = 0)
```

В масштабе функции связи мы моделируем линейную зависимость логарифмов мат. ожидания отклика от предикторов.


## График предсказаний в масштабе переменной-отклика

```{r}
ggplot(NewData, aes(x = Flowers, y = fit_mu, fill = Treatment)) +
  geom_ribbon(aes(ymin = lwr, 
                  ymax = upr), 
              alpha = 0.3) +
  geom_line(aes(colour = Treatment)) + 
  geom_hline(yintercept = 0)
```


GLM с отрицательным биномиальным распределением отклика моделирует его нелинейную связь предикторами за счет функции связи $log()$.


## GLM с отрицательным биномиальным распределением отклика

GLM с отрицательным биномиальным распределением отклика учитывает гетерогенность дисперсии ($E(y_i) = \mu_i$, $var(y_i) = \mu_i + \frac{\mu_i^2}{k}$). Стандартные ошибки возрастают с увеличением предсказанного значения даже сильнее, чем это было у Пуассоновской модели.

Этого оказалось вполне достаточно для моделирования данных (сверхдисперсии здесь нет).


```{r echo=FALSE}
ggplot(NewData, aes(x = Flowers, y = fit_mu, fill = Treatment)) +
  geom_ribbon(aes(ymin = lwr, 
                  ymax = upr), 
              alpha = 0.3) +
  geom_line(aes(colour = Treatment)) + 
  geom_hline(yintercept = 0) + ylab('Visits')
```


## Выводы

Число визитов опылителей на цветки гадючьего лука зависит не от присутствия вида вселенца или его цветов, а от разнообразия флоры на данном участке (тест отношения правдоподобий, $p = 0.02$).

При этом, чем больше цветов самого гадючьего лука, тем больше прилетает опылителей (тест отношения правдоподобий, $p = 0.01$).

```{r echo=FALSE}
ggplot(NewData, aes(x = Flowers, y = fit_mu, fill = Treatment)) +
  geom_ribbon(aes(ymin = lwr, 
                  ymax = upr), 
              alpha = 0.3) +
  geom_line(aes(colour = Treatment)) + 
  geom_hline(yintercept = 0) + 
  labs(y = 'Visits')
```


## Take-home messages

Очень важно правильно формулировать модель для данных.

Для моделирования счетных зависимых переменных применяются модели, основанные на распределении Пуассона или отрицательном биномиальном распределении.

Одно из условий применимости этих моделей --- отсутствие избыточности дисперсии.

Избыточность дисперсий может возникать в силу разных причин, поэтому единого рецепта борьбы с ней нет.

Квази-пуассоновские модели решают проблему сверхдисперсии в Пуассоновской GLM внося поправки для стандартных ошибок оценок коэффициентов модели.

Модели, основанные на отрицательном биномиальном распределении, учитывают избыточность дисперсии при помощи отдельного параметра.

## Что почитать

+ Zuur, A.F. and Ieno, E.N., 2016. A protocol for conducting and presenting results of regression-type analyses. Methods in Ecology and Evolution, 7(6), pp.636-645.
+ Кабаков Р.И. R в действии. Анализ и визуализация данных на языке R. М.: ДМК Пресс, 2014
+ Zuur, A., Ieno, E.N. and Smith, G.M., 2007. Analyzing ecological data. Springer Science & Business Media.
